# MySQL Optimization and Performance Rules
# Auto-generated by BugSearch2 - Database-Specific Rules
# Generated: 2025-10-14
# Category: database
# Target: MySQL Relational Database

rule:
  id: MYSQL_MISSING_INDEX
  category: database
  name: MySQL Query Without Index
  description: |
    Queries without proper indexes cause full table scans.
    Performance degrades exponentially with table size.

    Problems:
    - O(N) scan complexity (scans all rows)
    - Locks entire table during scan
    - High disk I/O
    - Query time proportional to table size

    Always create indexes on WHERE, JOIN, ORDER BY columns.
  base_severity: 9

  patterns:
    java:
      - pattern: 'WHERE\s+[a-zA-Z_][a-zA-Z0-9_]*\s*='
        context: 'SQL WHERE clause (check index)'
      - pattern: 'JOIN\s+\w+\s+ON\s+[a-zA-Z_][a-zA-Z0-9_]*\.'
        context: 'SQL JOIN clause (check index)'

    python:
      - pattern: 'WHERE\s+[a-zA-Z_][a-zA-Z0-9_]*\s*='
        context: 'Python SQL WHERE clause'

    php:
      - pattern: 'WHERE\s+[a-zA-Z_][a-zA-Z0-9_]*\s*='
        context: 'PHP SQL WHERE clause'

    csharp:
      - pattern: 'WHERE\s+[a-zA-Z_][a-zA-Z0-9_]*\s*='
        context: 'C# SQL WHERE clause'

    javascript:
      - pattern: 'WHERE\s+[a-zA-Z_][a-zA-Z0-9_]*\s*='
        context: 'JavaScript SQL WHERE clause'

  fixes:
    description: |
      Create indexes on frequently queried columns:

      -- Bad - No index (full table scan)
      SELECT * FROM users WHERE email = 'user@example.com';

      -- Good - Create index
      CREATE INDEX idx_users_email ON users(email);

      -- Better - Create unique index (enforces uniqueness)
      CREATE UNIQUE INDEX idx_users_email ON users(email);

      Composite index for multiple columns:
      CREATE INDEX idx_users_status_created ON users(status, created_at);

      Check index usage:
      EXPLAIN SELECT * FROM users WHERE email = 'user@example.com';

      Look for:
      - type: ALL (full table scan - BAD)
      - type: index (index scan - OK)
      - type: ref (index lookup - GOOD)
      - type: const (primary/unique key - BEST)

      Monitor slow queries:
      SET GLOBAL slow_query_log = 'ON';
      SET GLOBAL long_query_time = 1;  -- Log queries > 1 second

    references:
      - 'Index optimization: https://dev.mysql.com/doc/refman/8.0/en/optimization-indexes.html'
      - 'EXPLAIN output: https://dev.mysql.com/doc/refman/8.0/en/explain-output.html'

---

rule:
  id: MYSQL_NO_LIMIT
  category: database
  name: MySQL Query Without LIMIT
  description: |
    Queries without LIMIT can return millions of rows.
    Causes memory exhaustion and network saturation.

    Problems:
    - Application OOM (millions of objects)
    - Network bandwidth exhaustion
    - Long-running transactions
    - Table locks (for UPDATE/DELETE)

    Always use LIMIT for large result sets.
  base_severity: 8

  patterns:
    java:
      - pattern: 'SELECT.*FROM.*(?!LIMIT)'
        context: 'Java SQL SELECT without LIMIT'
      - pattern: 'createQuery\([^)]*\)\.getResultList\(\)(?!.*setMaxResults)'
        context: 'JPA query without setMaxResults'

    python:
      - pattern: 'SELECT.*FROM.*(?!LIMIT)'
        context: 'Python SQL SELECT without LIMIT'
      - pattern: 'query\.all\(\)(?!.*limit)'
        context: 'SQLAlchemy query without limit'

    php:
      - pattern: 'SELECT.*FROM.*(?!LIMIT)'
        context: 'PHP SQL SELECT without LIMIT'

    csharp:
      - pattern: 'SELECT.*FROM.*(?!LIMIT|TOP)'
        context: 'C# SQL SELECT without LIMIT/TOP'

  fixes:
    description: |
      Always add LIMIT for large tables:

      -- Bad - Returns all rows (potentially millions)
      SELECT * FROM logs WHERE level = 'ERROR';

      -- Good - Limit to reasonable number
      SELECT * FROM logs WHERE level = 'ERROR' LIMIT 100;

      -- Better - Paginate with OFFSET
      SELECT * FROM logs WHERE level = 'ERROR'
      ORDER BY created_at DESC
      LIMIT 100 OFFSET 0;  -- Page 1

      JPA example:
      TypedQuery<User> query = em.createQuery("SELECT u FROM User u", User.class);
      query.setMaxResults(100);  // Always set max results
      List<User> users = query.getResultList();

      SQLAlchemy example:
      users = session.query(User).limit(100).all()

      For bulk operations, use batch processing:
      -- Delete in batches
      DELETE FROM logs WHERE created_at < DATE_SUB(NOW(), INTERVAL 30 DAY)
      LIMIT 1000;
      -- Repeat until no rows affected

      Recommended LIMIT values:
      - Display lists: 20-100
      - API responses: 100-1000
      - Batch processing: 1000-10000

    references:
      - 'LIMIT optimization: https://dev.mysql.com/doc/refman/8.0/en/limit-optimization.html'

---

rule:
  id: MYSQL_MYISAM_ENGINE
  category: database
  name: MySQL MyISAM Storage Engine Usage
  description: |
    MyISAM is DEPRECATED and lacks critical features.
    Use InnoDB instead (default since MySQL 5.5).

    MyISAM problems:
    - No transaction support (no ACID)
    - No foreign key constraints
    - Table-level locking (not row-level)
    - No crash recovery
    - No MVCC (reads block writes)

    Always use InnoDB storage engine.
  base_severity: 9

  patterns:
    java:
      - pattern: 'ENGINE\s*=\s*MyISAM'
        context: 'SQL CREATE TABLE with MyISAM engine'

    python:
      - pattern: 'ENGINE\s*=\s*MyISAM'
        context: 'Python SQL MyISAM engine'

    php:
      - pattern: 'ENGINE\s*=\s*MyISAM'
        context: 'PHP SQL MyISAM engine'

  fixes:
    description: |
      Use InnoDB storage engine:

      -- Bad - MyISAM (deprecated)
      CREATE TABLE users (
        id INT PRIMARY KEY,
        name VARCHAR(100)
      ) ENGINE=MyISAM;

      -- Good - InnoDB (default, recommended)
      CREATE TABLE users (
        id INT PRIMARY KEY,
        name VARCHAR(100)
      ) ENGINE=InnoDB;

      Convert existing MyISAM tables:
      ALTER TABLE users ENGINE=InnoDB;

      Check table engines:
      SELECT table_name, engine
      FROM information_schema.tables
      WHERE table_schema = 'mydb';

      InnoDB advantages:
      - ACID transactions
      - Foreign keys
      - Row-level locking
      - Crash recovery (redo log)
      - MVCC (non-blocking reads)

      Configure InnoDB:
      innodb_buffer_pool_size = 70% of RAM  -- Critical for performance
      innodb_log_file_size = 256M           -- Redo log size
      innodb_flush_log_at_trx_commit = 1    -- Durability

    references:
      - 'InnoDB vs MyISAM: https://dev.mysql.com/doc/refman/8.0/en/innodb-introduction.html'
      - 'Storage engines: https://dev.mysql.com/doc/refman/8.0/en/storage-engines.html'

---

rule:
  id: MYSQL_NO_PREPARED_STATEMENT
  category: database
  name: MySQL Query Without Prepared Statement
  description: |
    String concatenation for SQL queries causes SQL injection.
    Also prevents query plan caching.

    Problems:
    - SQL injection vulnerability (CRITICAL)
    - No query plan reuse (performance)
    - Type safety issues

    Always use prepared statements with parameters.
  base_severity: 10

  patterns:
    java:
      - pattern: 'executeQuery\(["\'][^"\']*\+|executeQuery\([^"\']*\+.*["\']'
        context: 'Java JDBC executeQuery with string concatenation'
      - pattern: 'createStatement\(\)\.execute'
        context: 'Java Statement instead of PreparedStatement'

    python:
      - pattern: 'execute\(["\'][^"\']*%|execute\(["\'][^"\']*\+'
        context: 'Python SQL execute with string formatting'
      - pattern: 'execute\(f["\']'
        context: 'Python SQL execute with f-string'

    php:
      - pattern: 'query\(["\'][^"\']*\$|query\(["\'][^"\']*\.'
        context: 'PHP mysqli_query with string concatenation'

    csharp:
      - pattern: 'ExecuteReader\(["\'][^"\']*\+|ExecuteNonQuery\(["\'][^"\']*\+'
        context: 'C# SQL command with string concatenation'

    javascript:
      - pattern: 'query\(["\'][^"\']*\$\{|query\(`[^`]*\$\{'
        context: 'Node.js MySQL query with template literals'

  fixes:
    description: |
      Use prepared statements with parameterized queries:

      // Bad - SQL injection vulnerability!
      String email = request.getParameter("email");
      String sql = "SELECT * FROM users WHERE email = '" + email + "'";
      ResultSet rs = stmt.executeQuery(sql);
      // Attack: email = "' OR '1'='1"

      // Good - Prepared statement (safe)
      String sql = "SELECT * FROM users WHERE email = ?";
      PreparedStatement pstmt = conn.prepareStatement(sql);
      pstmt.setString(1, email);
      ResultSet rs = pstmt.executeQuery();

      Python example:
      # Bad
      cursor.execute(f"SELECT * FROM users WHERE email = '{email}'")

      # Good
      cursor.execute("SELECT * FROM users WHERE email = %s", (email,))

      PHP example:
      # Bad
      $result = mysqli_query($conn, "SELECT * FROM users WHERE email = '$email'");

      # Good
      $stmt = mysqli_prepare($conn, "SELECT * FROM users WHERE email = ?");
      mysqli_stmt_bind_param($stmt, "s", $email);
      mysqli_stmt_execute($stmt);

      Node.js example:
      // Bad
      connection.query(`SELECT * FROM users WHERE email = '${email}'`);

      // Good
      connection.query('SELECT * FROM users WHERE email = ?', [email]);

      Benefits:
      - Prevents SQL injection (CRITICAL)
      - Query plan caching (performance)
      - Type safety
      - Input validation

    references:
      - 'Prepared statements: https://dev.mysql.com/doc/refman/8.0/en/sql-prepared-statements.html'
      - 'SQL injection prevention: https://owasp.org/www-community/attacks/SQL_Injection'

---

rule:
  id: MYSQL_WRONG_ISOLATION_LEVEL
  category: database
  name: MySQL Inappropriate Transaction Isolation Level
  description: |
    Wrong isolation level causes data inconsistency or performance issues.

    Isolation levels (strictness order):
    1. READ UNCOMMITTED - Dirty reads (fastest, inconsistent)
    2. READ COMMITTED - Non-repeatable reads
    3. REPEATABLE READ - Phantom reads (MySQL default)
    4. SERIALIZABLE - No anomalies (slowest)

    Use REPEATABLE READ for most cases.
  base_severity: 7

  patterns:
    java:
      - pattern: 'TRANSACTION_READ_UNCOMMITTED'
        context: 'Java JDBC READ UNCOMMITTED isolation'
      - pattern: 'ISOLATION_READ_UNCOMMITTED'
        context: 'Spring @Transactional READ UNCOMMITTED'

    python:
      - pattern: 'isolation_level\s*=\s*["\']READ UNCOMMITTED["\']'
        context: 'Python SQLAlchemy READ UNCOMMITTED'

  fixes:
    description: |
      Choose appropriate isolation level:

      -- Bad - READ UNCOMMITTED (dirty reads)
      SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
      BEGIN;
      SELECT balance FROM accounts WHERE id = 1;  -- May read uncommitted data!
      COMMIT;

      -- Good - REPEATABLE READ (MySQL default)
      SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;
      BEGIN;
      SELECT balance FROM accounts WHERE id = 1;
      -- Same value if SELECT is repeated in this transaction
      COMMIT;

      Java example:
      // Bad
      conn.setTransactionIsolation(Connection.TRANSACTION_READ_UNCOMMITTED);

      // Good (default)
      conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);

      Isolation level selection:

      1. READ UNCOMMITTED:
         - Use case: Real-time analytics (OK to see inconsistent data)
         - Risk: Dirty reads, non-repeatable reads, phantom reads

      2. READ COMMITTED:
         - Use case: Most web applications (Oracle default)
         - Risk: Non-repeatable reads, phantom reads

      3. REPEATABLE READ:
         - Use case: Financial transactions (MySQL default)
         - Risk: Phantom reads (mitigated by gap locking in InnoDB)

      4. SERIALIZABLE:
         - Use case: Banking, critical data (avoid if possible)
         - Risk: Performance degradation, deadlocks

      Check current isolation level:
      SELECT @@transaction_isolation;

    references:
      - 'Transaction isolation: https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html'
      - 'ACID properties: https://dev.mysql.com/doc/refman/8.0/en/mysql-acid.html'

---

rule:
  id: MYSQL_NO_CONNECTION_POOL
  category: database
  name: MySQL Connection Creation Without Pooling
  description: |
    Creating new connections for each query is extremely expensive.
    TCP handshake + authentication + resource allocation overhead.

    Problems:
    - Connection overhead: 50-100ms per connection
    - Resource exhaustion (file descriptors, memory)
    - Poor scalability

    Always use connection pooling.
  base_severity: 9

  patterns:
    java:
      - pattern: 'DriverManager\.getConnection\([^)]+\)'
        context: 'Java JDBC direct connection (should use pool)'
      - pattern: 'new\s+Connection\('
        context: 'Java new Connection instance'

    python:
      - pattern: 'mysql\.connector\.connect\('
        context: 'Python MySQL direct connection'
      - pattern: 'MySQLdb\.connect\('
        context: 'Python MySQLdb direct connection'

    php:
      - pattern: 'mysqli_connect\('
        context: 'PHP mysqli_connect (should use persistent)'
      - pattern: 'new\s+mysqli\('
        context: 'PHP new mysqli instance'

    csharp:
      - pattern: 'new\s+MySqlConnection\('
        context: 'C# new MySqlConnection (should use pool)'

    javascript:
      - pattern: 'mysql\.createConnection\('
        context: 'Node.js mysql.createConnection (should use pool)'

  fixes:
    description: |
      Use connection pooling:

      // Bad - New connection for each request
      Connection conn = DriverManager.getConnection(url, user, password);
      // ... execute queries
      conn.close();  // Expensive!

      // Good - Connection pool (HikariCP recommended)
      HikariConfig config = new HikariConfig();
      config.setJdbcUrl(url);
      config.setUsername(user);
      config.setPassword(password);
      config.setMaximumPoolSize(10);
      config.setMinimumIdle(5);
      HikariDataSource ds = new HikariDataSource(config);

      Connection conn = ds.getConnection();  // From pool (fast!)
      // ... execute queries
      conn.close();  // Returns to pool

      Python example:
      from mysql.connector import pooling

      pool = pooling.MySQLConnectionPool(
          pool_name="mypool",
          pool_size=10,
          host="localhost",
          user="user",
          password="password",
          database="mydb"
      )

      conn = pool.get_connection()  # From pool
      # ... execute queries
      conn.close()  # Returns to pool

      Node.js example:
      const mysql = require('mysql2');

      const pool = mysql.createPool({
          host: 'localhost',
          user: 'user',
          password: 'password',
          database: 'mydb',
          waitForConnections: true,
          connectionLimit: 10,
          queueLimit: 0
      });

      pool.execute('SELECT * FROM users', (err, rows) => {
          // Connection automatically returned to pool
      });

      Connection pool sizing:
      - connections = ((core_count * 2) + effective_spindle_count)
      - For web app: 10-20 connections per app server
      - Monitor: active connections, wait time

    references:
      - 'Connection pooling: https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-usagenotes-j2ee-concepts-connection-pooling.html'
      - 'HikariCP: https://github.com/brettwooldridge/HikariCP'

---

rule:
  id: MYSQL_IMPLICIT_TYPE_CONVERSION
  category: database
  name: MySQL Implicit Type Conversion in WHERE Clause
  description: |
    Implicit type conversion prevents index usage.
    Forces full table scan even with index.

    Problems:
    - Index not used (type mismatch)
    - Full table scan (O(N))
    - Slow query performance

    Always match column type in WHERE clause.
  base_severity: 8

  patterns:
    java:
      - pattern: 'WHERE\s+\w+\s*=\s*["\']?\d+["\']?'
        context: 'SQL WHERE with potential type mismatch'

    python:
      - pattern: 'WHERE\s+\w+\s*=\s*["\']?\d+["\']?'
        context: 'Python SQL type conversion issue'

  fixes:
    description: |
      Match column type in queries:

      -- Table definition
      CREATE TABLE users (
        id INT PRIMARY KEY,
        status VARCHAR(20),
        created_at TIMESTAMP
      );
      CREATE INDEX idx_users_status ON users(status);

      -- Bad - String comparison on INT (index not used)
      SELECT * FROM users WHERE id = '123';  -- '123' is string!

      -- Good - INT comparison (index used)
      SELECT * FROM users WHERE id = 123;

      -- Bad - INT comparison on VARCHAR (index not used)
      SELECT * FROM users WHERE status = 1;  -- status is VARCHAR!

      -- Good - String comparison (index used)
      SELECT * FROM users WHERE status = 'active';

      Check with EXPLAIN:
      EXPLAIN SELECT * FROM users WHERE id = '123';
      -- Look for: possible_keys: NULL (index not used)

      EXPLAIN SELECT * FROM users WHERE id = 123;
      -- Look for: possible_keys: PRIMARY (index used)

      Common type mismatches:
      - INT column with string value: WHERE id = '123'
      - VARCHAR column with numeric value: WHERE status = 1
      - DATE column with string: WHERE date = '2024-01-01' (OK if format correct)

      PreparedStatement automatically handles types:
      pstmt.setInt(1, 123);  // Correct type
      pstmt.setString(2, "active");  // Correct type

    references:
      - 'Type conversion: https://dev.mysql.com/doc/refman/8.0/en/type-conversion.html'
      - 'Index optimization: https://dev.mysql.com/doc/refman/8.0/en/optimization-indexes.html'
