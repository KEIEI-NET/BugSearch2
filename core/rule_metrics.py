"""
ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

Phase 4.2ã®æ–°æ©Ÿèƒ½:
- ãƒ«ãƒ¼ãƒ«ã”ã¨ã®æ¤œå‡ºçµ±è¨ˆ
- èª¤æ¤œçŸ¥ç‡ã®è¿½è·¡
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ°¸ç¶šåŒ–

ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v4.5.0 (Phase 4.2)
ä½œæˆæ—¥: 2025å¹´10æœˆ12æ—¥ JST

@perfectå“è³ª:
- ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªå®Ÿè£…
- åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ 
- è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

from pathlib import Path
from typing import Dict, List, Optional, Set
from datetime import datetime
from dataclasses import dataclass, asdict, field
import json
import threading


@dataclass
class RuleMetric:
    """
    ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹

    æ¤œå‡ºçµ±è¨ˆã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’ä¿æŒ
    """
    rule_id: str
    total_detections: int = 0
    unique_files: Set[str] = field(default_factory=set)
    false_positives: int = 0
    execution_time_ms: float = 0.0
    execution_count: int = 0
    last_execution: str = ""

    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›ï¼ˆJSONåŒ–ã®ãŸã‚ï¼‰"""
        return {
            'rule_id': self.rule_id,
            'total_detections': self.total_detections,
            'unique_files': list(self.unique_files),
            'unique_file_count': len(self.unique_files),
            'false_positives': self.false_positives,
            'execution_time_ms': self.execution_time_ms,
            'execution_count': self.execution_count,
            'average_execution_time_ms': (
                self.execution_time_ms / self.execution_count
                if self.execution_count > 0 else 0.0
            ),
            'last_execution': self.last_execution
        }

    @classmethod
    def from_dict(cls, data: Dict) -> 'RuleMetric':
        """è¾æ›¸ã‹ã‚‰å¾©å…ƒ"""
        return cls(
            rule_id=data['rule_id'],
            total_detections=data.get('total_detections', 0),
            unique_files=set(data.get('unique_files', [])),
            false_positives=data.get('false_positives', 0),
            execution_time_ms=data.get('execution_time_ms', 0.0),
            execution_count=data.get('execution_count', 0),
            last_execution=data.get('last_execution', '')
        )


class RuleMetricsCollector:
    """
    ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

    Phase 4.2ã®æ–°æ©Ÿèƒ½:
    - ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    - æ°¸ç¶šåŒ–æ©Ÿèƒ½
    - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆ
    """

    def __init__(self, metrics_file: Path = Path(".bugsearch/metrics.json")):
        """
        åˆæœŸåŒ–

        Args:
            metrics_file: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.metrics_file = metrics_file
        self.metrics: Dict[str, RuleMetric] = {}
        self._lock = threading.Lock()
        self._auto_save = True
        self._load_metrics()

    def _load_metrics(self):
        """æ—¢å­˜ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿"""
        if not self.metrics_file.exists():
            return

        try:
            with open(self.metrics_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            for rule_id, metric_data in data.items():
                self.metrics[rule_id] = RuleMetric.from_dict(metric_data)

            print(f"[OK] ãƒ¡ãƒˆãƒªã‚¯ã‚¹èª­ã¿è¾¼ã¿å®Œäº†: {len(self.metrics)}å€‹ã®ãƒ«ãƒ¼ãƒ«")

        except Exception as e:
            print(f"[WARNING] ãƒ¡ãƒˆãƒªã‚¯ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def _save_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜"""
        try:
            self.metrics_file.parent.mkdir(parents=True, exist_ok=True)

            data = {rule_id: metric.to_dict() for rule_id, metric in self.metrics.items()}

            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

        except Exception as e:
            print(f"[ERROR] ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜å¤±æ•—: {e}")

    def record_detection(
        self,
        rule_id: str,
        file_path: str,
        execution_time_ms: float = 0.0
    ):
        """
        æ¤œå‡ºã‚’è¨˜éŒ²

        Args:
            rule_id: ãƒ«ãƒ¼ãƒ«ID
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            execution_time_ms: å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
        """
        with self._lock:
            if rule_id not in self.metrics:
                self.metrics[rule_id] = RuleMetric(rule_id=rule_id)

            metric = self.metrics[rule_id]
            metric.total_detections += 1
            metric.unique_files.add(file_path)
            metric.execution_time_ms += execution_time_ms
            metric.execution_count += 1
            metric.last_execution = datetime.now().isoformat()

            if self._auto_save:
                self._save_metrics()

    def record_false_positive(self, rule_id: str):
        """
        èª¤æ¤œçŸ¥ã‚’è¨˜éŒ²

        Args:
            rule_id: ãƒ«ãƒ¼ãƒ«ID
        """
        with self._lock:
            if rule_id in self.metrics:
                self.metrics[rule_id].false_positives += 1

                if self._auto_save:
                    self._save_metrics()
            else:
                print(f"[WARNING] ãƒ«ãƒ¼ãƒ« '{rule_id}' ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

    def get_metrics(self, rule_id: str) -> Optional[RuleMetric]:
        """
        ç‰¹å®šãƒ«ãƒ¼ãƒ«ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—

        Args:
            rule_id: ãƒ«ãƒ¼ãƒ«ID

        Returns:
            ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneï¼‰
        """
        return self.metrics.get(rule_id)

    def get_all_metrics(self) -> List[RuleMetric]:
        """
        å…¨ãƒ«ãƒ¼ãƒ«ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—

        Returns:
            ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        return list(self.metrics.values())

    def get_false_positive_rate(self, rule_id: str) -> float:
        """
        èª¤æ¤œçŸ¥ç‡ã‚’è¨ˆç®—

        Args:
            rule_id: ãƒ«ãƒ¼ãƒ«ID

        Returns:
            èª¤æ¤œçŸ¥ç‡ï¼ˆ0.0-1.0ï¼‰
        """
        metric = self.metrics.get(rule_id)
        if not metric or metric.total_detections == 0:
            return 0.0

        return metric.false_positives / metric.total_detections

    def get_average_execution_time(self, rule_id: str) -> float:
        """
        å¹³å‡å®Ÿè¡Œæ™‚é–“ã‚’å–å¾—

        Args:
            rule_id: ãƒ«ãƒ¼ãƒ«ID

        Returns:
            å¹³å‡å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
        """
        metric = self.metrics.get(rule_id)
        if not metric or metric.execution_count == 0:
            return 0.0

        return metric.execution_time_ms / metric.execution_count

    def get_top_rules_by_detections(self, limit: int = 10) -> List[RuleMetric]:
        """
        æ¤œå‡ºæ•°ãŒå¤šã„ãƒ«ãƒ¼ãƒ«ã‚’å–å¾—

        Args:
            limit: å–å¾—æ•°

        Returns:
            ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆæ¤œå‡ºæ•°é™é †ï¼‰
        """
        return sorted(
            self.metrics.values(),
            key=lambda m: m.total_detections,
            reverse=True
        )[:limit]

    def get_top_rules_by_false_positives(self, limit: int = 10) -> List[RuleMetric]:
        """
        èª¤æ¤œçŸ¥ç‡ãŒé«˜ã„ãƒ«ãƒ¼ãƒ«ã‚’å–å¾—

        Args:
            limit: å–å¾—æ•°

        Returns:
            ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆèª¤æ¤œçŸ¥ç‡é™é †ï¼‰
        """
        rules_with_fp = [
            m for m in self.metrics.values()
            if m.total_detections > 0
        ]

        return sorted(
            rules_with_fp,
            key=lambda m: m.false_positives / m.total_detections,
            reverse=True
        )[:limit]

    def get_slowest_rules(self, limit: int = 10) -> List[RuleMetric]:
        """
        å®Ÿè¡ŒãŒé…ã„ãƒ«ãƒ¼ãƒ«ã‚’å–å¾—

        Args:
            limit: å–å¾—æ•°

        Returns:
            ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆå¹³å‡å®Ÿè¡Œæ™‚é–“é™é †ï¼‰
        """
        rules_with_execution = [
            m for m in self.metrics.values()
            if m.execution_count > 0
        ]

        return sorted(
            rules_with_execution,
            key=lambda m: m.execution_time_ms / m.execution_count,
            reverse=True
        )[:limit]

    def reset_metrics(self, rule_id: Optional[str] = None):
        """
        ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ

        Args:
            rule_id: ãƒ«ãƒ¼ãƒ«IDï¼ˆNoneã®å ´åˆã¯å…¨ãƒ«ãƒ¼ãƒ«ï¼‰
        """
        with self._lock:
            if rule_id:
                if rule_id in self.metrics:
                    del self.metrics[rule_id]
                    print(f"[OK] ãƒ«ãƒ¼ãƒ« '{rule_id}' ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                else:
                    print(f"[WARNING] ãƒ«ãƒ¼ãƒ« '{rule_id}' ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            else:
                self.metrics.clear()
                print("[OK] å…¨ãƒ«ãƒ¼ãƒ«ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

            self._save_metrics()

    def generate_report(self, detailed: bool = True) -> str:
        """
        ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            detailed: è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‹

        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—
        """
        lines = [
            "=" * 80,
            "ğŸ“Š ãƒ«ãƒ¼ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ",
            "=" * 80,
            "",
            f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"è¿½è·¡ä¸­ã®ãƒ«ãƒ¼ãƒ«æ•°: {len(self.metrics)}å€‹",
            ""
        ]

        if not self.metrics:
            lines.append("[INFO] ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return "\n".join(lines)

        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        total_detections = sum(m.total_detections for m in self.metrics.values())
        total_files = len(set().union(*(m.unique_files for m in self.metrics.values())))
        total_fps = sum(m.false_positives for m in self.metrics.values())

        lines.extend([
            "ğŸ“ˆ ã‚µãƒãƒªãƒ¼çµ±è¨ˆ:",
            f"  ç·æ¤œå‡ºæ•°: {total_detections}ä»¶",
            f"  å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}ä»¶",
            f"  ç·èª¤æ¤œçŸ¥æ•°: {total_fps}ä»¶",
            ""
        ])

        # Top 5 æ¤œå‡ºæ•°
        top_detections = self.get_top_rules_by_detections(limit=5)
        if top_detections:
            lines.extend([
                "ğŸ” Top 5 æ¤œå‡ºæ•°ãŒå¤šã„ãƒ«ãƒ¼ãƒ«:",
                ""
            ])
            for i, metric in enumerate(top_detections, 1):
                lines.append(f"  {i}. {metric.rule_id}: {metric.total_detections}ä»¶")
            lines.append("")

        # Top 5 èª¤æ¤œçŸ¥ç‡
        top_fp_rules = self.get_top_rules_by_false_positives(limit=5)
        if top_fp_rules:
            lines.extend([
                "âš ï¸  Top 5 èª¤æ¤œçŸ¥ç‡ãŒé«˜ã„ãƒ«ãƒ¼ãƒ«:",
                ""
            ])
            for i, metric in enumerate(top_fp_rules, 1):
                fp_rate = self.get_false_positive_rate(metric.rule_id)
                lines.append(
                    f"  {i}. {metric.rule_id}: {fp_rate * 100:.1f}% "
                    f"({metric.false_positives}/{metric.total_detections})"
                )
            lines.append("")

        # Top 5 å®Ÿè¡Œæ™‚é–“
        slowest_rules = self.get_slowest_rules(limit=5)
        if slowest_rules:
            lines.extend([
                "ğŸŒ Top 5 å®Ÿè¡ŒãŒé…ã„ãƒ«ãƒ¼ãƒ«:",
                ""
            ])
            for i, metric in enumerate(slowest_rules, 1):
                avg_time = self.get_average_execution_time(metric.rule_id)
                lines.append(f"  {i}. {metric.rule_id}: {avg_time:.2f}ms")
            lines.append("")

        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
        if detailed:
            lines.extend([
                "-" * 80,
                "ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ:",
                "-" * 80,
                ""
            ])

            for rule_id, metric in sorted(self.metrics.items()):
                fp_rate = self.get_false_positive_rate(rule_id)
                avg_time = self.get_average_execution_time(rule_id)

                lines.append(f"â–  {rule_id}")
                lines.append(f"  æ¤œå‡ºæ•°: {metric.total_detections}ä»¶")
                lines.append(f"  å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(metric.unique_files)}ä»¶")
                lines.append(f"  èª¤æ¤œçŸ¥: {metric.false_positives}ä»¶ ({fp_rate * 100:.1f}%)")
                lines.append(f"  å®Ÿè¡Œå›æ•°: {metric.execution_count}å›")
                lines.append(f"  å¹³å‡å®Ÿè¡Œæ™‚é–“: {avg_time:.2f}ms")
                lines.append(f"  æœ€çµ‚å®Ÿè¡Œ: {metric.last_execution}")
                lines.append("")

        lines.append("=" * 80)

        return "\n".join(lines)

    def export_to_json(self, output_file: Path):
        """
        ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

        Args:
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            data = {
                'metadata': {
                    'exported_at': datetime.now().isoformat(),
                    'total_rules': len(self.metrics)
                },
                'metrics': {rule_id: metric.to_dict() for rule_id, metric in self.metrics.items()}
            }

            output_file.parent.mkdir(parents=True, exist_ok=True)

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            print(f"[OK] ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {output_file}")

        except Exception as e:
            print(f"[ERROR] ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
