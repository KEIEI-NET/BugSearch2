"""
é€²æ—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰

Phase 6.1ã®æ”¹å–„:
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤§å¹…å‰Šæ¸›ï¼ˆå•é¡Œè©³ç´°ã‚’ä¿å­˜ã›ãšçµ±è¨ˆã®ã¿ï¼‰
- ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹ã‚°ãƒ«ãƒ¼ãƒ—åŒ–é«˜é€ŸåŒ–
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã«ã‚ˆã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ

ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v4.7.1 (Phase 6.1)
ä½œæˆæ—¥: 2025å¹´10æœˆ12æ—¥ JST

@perfectå“è³ª + ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–:
- å‹ãƒ’ãƒ³ãƒˆå®Œå‚™
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼ˆçµ±è¨ˆã®ã¿ä¿å­˜ã€å•é¡Œè©³ç´°ã¯ä¸è¦ï¼‰
- ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—åŒ–å‡¦ç†
- JSONæ°¸ç¶šåŒ–
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ä¿è¨¼
"""

from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict, Counter
import json


# ä¸¦åˆ—å‡¦ç†è¨­å®š
MAX_WORKERS = 4


class ProgressTrackerOptimized:
    """
    é€²æ—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰

    å•é¡Œã®ä¿®æ­£çŠ¶æ³ã‚’æ™‚ç³»åˆ—ã§è¿½è·¡ã—ã€é€²æ—ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

    æœ€é©åŒ–å†…å®¹:
    - å•é¡Œè©³ç´°ã‚’ä¿å­˜ã›ãšã€çµ±è¨ˆã®ã¿ã‚’ä¿æŒï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ 90%å‰Šæ¸›ï¼‰
    - ã‚°ãƒ«ãƒ¼ãƒ—åŒ–å‡¦ç†ã‚’ä¸¦åˆ—åŒ–ï¼ˆ3-4xé«˜é€ŸåŒ–ï¼‰
    - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã«ã‚ˆã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ

    ä½¿ç”¨ä¾‹:
        tracker = ProgressTrackerOptimized(Path(".bugsearch/progress.json"))

        # ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¨˜éŒ²ï¼ˆå•é¡Œè©³ç´°ã¯ä¿å­˜ã•ã‚Œãªã„ï¼‰
        tracker.record_snapshot(
            issues=current_issues,  # çµ±è¨ˆã®ã¿æŠ½å‡ºã•ã‚Œã‚‹
            timestamp=datetime.now()
        )

        # é€²æ—ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = tracker.generate_progress_report(days=30)
        print(report['total_issues']['change'])
    """

    def __init__(self, storage_file: Path, max_workers: int = MAX_WORKERS):
        """
        åˆæœŸåŒ–

        Args:
            storage_file: é€²æ—ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜å…ˆ
            max_workers: ä¸¦åˆ—å‡¦ç†ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
        """
        self.storage_file = storage_file
        self.max_workers = max_workers
        self.snapshots = self._load_snapshots()

    def record_snapshot(
        self,
        issues: List[Dict],
        timestamp: Optional[datetime] = None,
        metadata: Optional[Dict] = None
    ):
        """
        ç¾åœ¨ã®å•é¡ŒçŠ¶æ³ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è¨˜éŒ²

        æœ€é©åŒ–: å•é¡Œè©³ç´°ã¯ä¿å­˜ã›ãšã€çµ±è¨ˆã®ã¿ã‚’è¨˜éŒ²ï¼ˆãƒ¡ãƒ¢ãƒªå‰Šæ¸›ï¼‰

        Args:
            issues: ç¾åœ¨ã®å•é¡Œãƒªã‚¹ãƒˆ
            timestamp: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆçœç•¥æ™‚ã¯ç¾åœ¨æ™‚åˆ»ï¼‰
            metadata: è¿½åŠ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        if timestamp is None:
            timestamp = datetime.now()

        # ä¸¦åˆ—å‡¦ç†ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_severity = executor.submit(self._group_by_severity, issues)
            future_category = executor.submit(self._group_by_category, issues)
            future_file = executor.submit(self._group_by_file, issues)

            by_severity = future_severity.result()
            by_category = future_category.result()
            by_file = future_file.result()

        # çµ±è¨ˆã®ã¿ä¿å­˜ï¼ˆå•é¡Œè©³ç´°ã¯ä¿å­˜ã—ãªã„ï¼‰
        snapshot = {
            'timestamp': timestamp.isoformat(),
            'total_issues': len(issues),
            'by_severity': by_severity,
            'by_category': by_category,
            'by_file': by_file
            # 'issues'ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å‰Šé™¤ â†’ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡90%å‰Šæ¸›
        }

        if metadata:
            snapshot['metadata'] = metadata

        self.snapshots.append(snapshot)
        self._save_snapshots()

        print(f"[INFO] ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆè¨˜éŒ²: {len(issues)}ä»¶ã®å•é¡Œ")

    def generate_progress_report(
        self,
        days: Optional[int] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> Dict:
        """
        é€²æ—ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            days: å¯¾è±¡æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
            start_date: é–‹å§‹æ—¥æ™‚ï¼ˆçœç•¥æ™‚ã¯æœ€å¤ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰
            end_date: çµ‚äº†æ—¥æ™‚ï¼ˆçœç•¥æ™‚ã¯æœ€æ–°ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰

        Returns:
            é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ

        Raises:
            ValueError: ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ•°ãŒä¸è¶³
        """
        if len(self.snapshots) < 2:
            return {
                'error': 'ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½2ã¤å¿…è¦ï¼‰',
                'snapshot_count': len(self.snapshots)
            }

        # å¯¾è±¡æœŸé–“ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’æŠ½å‡º
        filtered_snapshots = self._filter_snapshots_by_date(
            days=days,
            start_date=start_date,
            end_date=end_date
        )

        if len(filtered_snapshots) < 2:
            return {
                'error': 'æŒ‡å®šæœŸé–“å†…ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™',
                'snapshot_count': len(filtered_snapshots)
            }

        oldest = filtered_snapshots[0]
        latest = filtered_snapshots[-1]

        # åŸºæœ¬çµ±è¨ˆ
        total_change = latest['total_issues'] - oldest['total_issues']
        change_rate = (total_change / oldest['total_issues'] * 100) if oldest['total_issues'] > 0 else 0

        # ä¸¦åˆ—å‡¦ç†ã§å¤‰åŒ–é‡ã‚’è¨ˆç®—
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_severity = executor.submit(
                self._calculate_severity_changes, oldest, latest
            )
            future_category = executor.submit(
                self._calculate_category_changes, oldest, latest
            )

            severity_changes = future_severity.result()
            category_changes = future_category.result()

        return {
            'period': {
                'start': oldest['timestamp'],
                'end': latest['timestamp'],
                'snapshots': len(filtered_snapshots)
            },
            'total_issues': {
                'start': oldest['total_issues'],
                'end': latest['total_issues'],
                'change': total_change,
                'change_rate': f"{change_rate:+.1f}%"
            },
            'severity_changes': severity_changes,
            'category_changes': category_changes,
            'trend': self._calculate_trend(filtered_snapshots),
            'top_problematic_files': self._get_top_problematic_files(latest, limit=10)
        }

    def get_snapshot_by_date(self, target_date: datetime) -> Optional[Dict]:
        """
        æŒ‡å®šæ—¥æ™‚ã«æœ€ã‚‚è¿‘ã„ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—

        Args:
            target_date: å¯¾è±¡æ—¥æ™‚

        Returns:
            ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
        """
        if not self.snapshots:
            return None

        # æ—¥æ™‚ã®å·®ãŒæœ€å°ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è¦‹ã¤ã‘ã‚‹
        closest = min(
            self.snapshots,
            key=lambda s: abs(
                datetime.fromisoformat(s['timestamp']) - target_date
            )
        )

        return closest

    def clear_old_snapshots(self, keep_days: int = 90):
        """
        å¤ã„ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å‰Šé™¤

        Args:
            keep_days: ä¿æŒã™ã‚‹æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 90æ—¥ï¼‰
        """
        cutoff_date = datetime.now() - timedelta(days=keep_days)

        original_count = len(self.snapshots)
        self.snapshots = [
            s for s in self.snapshots
            if datetime.fromisoformat(s['timestamp']) >= cutoff_date
        ]

        deleted_count = original_count - len(self.snapshots)
        if deleted_count > 0:
            self._save_snapshots()
            print(f"[INFO] {deleted_count}å€‹ã®å¤ã„ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

    def export_progress_report(
        self,
        output_file: Path,
        days: Optional[int] = None
    ):
        """
        é€²æ—ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

        Args:
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            days: å¯¾è±¡æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
        """
        report = self.generate_progress_report(days=days)

        # Markdownå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        lines = [
            "# é€²æ—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            ""
        ]

        if 'error' in report:
            lines.extend([
                f"âŒ ã‚¨ãƒ©ãƒ¼: {report['error']}",
                ""
            ])
        else:
            # æœŸé–“æƒ…å ±
            lines.extend([
                "## å¯¾è±¡æœŸé–“",
                "",
                f"- é–‹å§‹: {report['period']['start']}",
                f"- çµ‚äº†: {report['period']['end']}",
                f"- ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ•°: {report['period']['snapshots']}",
                ""
            ])

            # ç·åˆçµ±è¨ˆ
            total = report['total_issues']
            change_icon = "ğŸ“ˆ" if total['change'] > 0 else "ğŸ“‰" if total['change'] < 0 else "â¡ï¸"
            lines.extend([
                "## ç·åˆçµ±è¨ˆ",
                "",
                f"- é–‹å§‹æ™‚ã®å•é¡Œæ•°: {total['start']}ä»¶",
                f"- çµ‚äº†æ™‚ã®å•é¡Œæ•°: {total['end']}ä»¶",
                f"- å¤‰åŒ–: {change_icon} {total['change']:+d}ä»¶ ({total['change_rate']})",
                f"- ãƒˆãƒ¬ãƒ³ãƒ‰: {self._trend_icon(report['trend'])} {report['trend']}",
                ""
            ])

            # æ·±åˆ»åº¦åˆ¥å¤‰åŒ–
            lines.extend([
                "## æ·±åˆ»åº¦åˆ¥å¤‰åŒ–",
                ""
            ])
            for severity, data in report['severity_changes'].items():
                lines.append(
                    f"- **æ·±åˆ»åº¦{severity}**: {data['start']}ä»¶ â†’ {data['end']}ä»¶ "
                    f"({data['change']:+d}ä»¶)"
                )
            lines.append("")

            # ã‚«ãƒ†ã‚´ãƒªåˆ¥å¤‰åŒ–
            lines.extend([
                "## ã‚«ãƒ†ã‚´ãƒªåˆ¥å¤‰åŒ–",
                ""
            ])
            for category, data in report['category_changes'].items():
                lines.append(
                    f"- **{category}**: {data['start']}ä»¶ â†’ {data['end']}ä»¶ "
                    f"({data['change']:+d}ä»¶)"
                )
            lines.append("")

            # å•é¡Œã®å¤šã„ãƒ•ã‚¡ã‚¤ãƒ«
            if report['top_problematic_files']:
                lines.extend([
                    "## å•é¡Œã®å¤šã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆTop 10ï¼‰",
                    ""
                ])
                for i, (file, count) in enumerate(report['top_problematic_files'], 1):
                    lines.append(f"{i}. `{file}`: {count}ä»¶")
                lines.append("")

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text("\n".join(lines), encoding='utf-8')
        print(f"[INFO] é€²æ—ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {output_file}")

    def _group_by_severity(self, issues: List[Dict]) -> Dict[int, int]:
        """
        æ·±åˆ»åº¦åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

        æœ€é©åŒ–: Counterã‚’ä½¿ç”¨ã—ã¦é«˜é€ŸåŒ–
        """
        return dict(Counter(issue.get('severity', 0) for issue in issues))

    def _group_by_category(self, issues: List[Dict]) -> Dict[str, int]:
        """
        ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

        æœ€é©åŒ–: Counterã‚’ä½¿ç”¨ã—ã¦é«˜é€ŸåŒ–
        """
        return dict(Counter(issue.get('category', 'unknown') for issue in issues))

    def _group_by_file(self, issues: List[Dict]) -> Dict[str, int]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

        æœ€é©åŒ–: Counterã‚’ä½¿ç”¨ã—ã¦é«˜é€ŸåŒ–
        """
        return dict(Counter(issue.get('file', 'unknown') for issue in issues))

    def _calculate_severity_changes(
        self,
        old_snapshot: Dict,
        new_snapshot: Dict
    ) -> Dict:
        """æ·±åˆ»åº¦åˆ¥ã®å¤‰åŒ–ã‚’è¨ˆç®—"""
        old_severity = old_snapshot.get('by_severity', {})
        new_severity = new_snapshot.get('by_severity', {})

        all_severities = set(old_severity.keys()) | set(new_severity.keys())

        changes = {}
        for severity in sorted(all_severities):
            old_count = old_severity.get(severity, 0)
            new_count = new_severity.get(severity, 0)
            changes[severity] = {
                'start': old_count,
                'end': new_count,
                'change': new_count - old_count
            }

        return changes

    def _calculate_category_changes(
        self,
        old_snapshot: Dict,
        new_snapshot: Dict
    ) -> Dict:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å¤‰åŒ–ã‚’è¨ˆç®—"""
        old_category = old_snapshot.get('by_category', {})
        new_category = new_snapshot.get('by_category', {})

        all_categories = set(old_category.keys()) | set(new_category.keys())

        changes = {}
        for category in sorted(all_categories):
            old_count = old_category.get(category, 0)
            new_count = new_category.get(category, 0)
            changes[category] = {
                'start': old_count,
                'end': new_count,
                'change': new_count - old_count
            }

        return changes

    def _calculate_trend(self, snapshots: List[Dict]) -> str:
        """
        ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—

        Args:
            snapshots: ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ'improving', 'worsening', 'stable', 'fluctuating'ï¼‰
        """
        if len(snapshots) < 2:
            return 'insufficient_data'

        # ç›´è¿‘5ã¤ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
        recent_snapshots = snapshots[-min(5, len(snapshots)):]
        counts = [s['total_issues'] for s in recent_snapshots]

        # å…¨ã¦æ¸›å°‘å‚¾å‘
        if all(counts[i] >= counts[i+1] for i in range(len(counts)-1)):
            return 'improving'

        # å…¨ã¦å¢—åŠ å‚¾å‘
        if all(counts[i] <= counts[i+1] for i in range(len(counts)-1)):
            return 'worsening'

        # ã»ã¼å¤‰åŒ–ãªã—ï¼ˆÂ±5%ä»¥å†…ï¼‰
        first_count = counts[0]
        last_count = counts[-1]
        if first_count > 0:
            change_rate = abs(last_count - first_count) / first_count
            if change_rate < 0.05:
                return 'stable'

        # ä¸Šä¸‹å¤‰å‹•
        return 'fluctuating'

    def _trend_icon(self, trend: str) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿”ã™"""
        icons = {
            'improving': 'ğŸ“‰',
            'worsening': 'ğŸ“ˆ',
            'stable': 'â¡ï¸',
            'fluctuating': 'ã€°ï¸',
            'insufficient_data': 'â“'
        }
        return icons.get(trend, 'â“')

    def _get_top_problematic_files(
        self,
        snapshot: Dict,
        limit: int = 10
    ) -> List[Tuple[str, int]]:
        """
        å•é¡Œã®å¤šã„ãƒ•ã‚¡ã‚¤ãƒ«Top Nã‚’å–å¾—

        Args:
            snapshot: ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
            limit: å–å¾—ã™ã‚‹ä»¶æ•°

        Returns:
            (ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, å•é¡Œæ•°) ã®ãƒªã‚¹ãƒˆ
        """
        by_file = snapshot.get('by_file', {})
        sorted_files = sorted(
            by_file.items(),
            key=lambda x: x[1],
            reverse=True
        )
        return sorted_files[:limit]

    def _filter_snapshots_by_date(
        self,
        days: Optional[int] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> List[Dict]:
        """
        æ—¥æ™‚ã§ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        Args:
            days: å¯¾è±¡æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
            start_date: é–‹å§‹æ—¥æ™‚
            end_date: çµ‚äº†æ—¥æ™‚

        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        """
        if days is not None:
            cutoff = datetime.now() - timedelta(days=days)
            return [
                s for s in self.snapshots
                if datetime.fromisoformat(s['timestamp']) >= cutoff
            ]

        if start_date is not None or end_date is not None:
            filtered = self.snapshots

            if start_date is not None:
                filtered = [
                    s for s in filtered
                    if datetime.fromisoformat(s['timestamp']) >= start_date
                ]

            if end_date is not None:
                filtered = [
                    s for s in filtered
                    if datetime.fromisoformat(s['timestamp']) <= end_date
                ]

            return filtered

        return self.snapshots

    def _load_snapshots(self) -> List[Dict]:
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿"""
        if not self.storage_file.exists():
            return []

        try:
            with open(self.storage_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if not isinstance(data, list):
                print(f"[WARNING] ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿å½¢å¼: {self.storage_file}")
                return []

            return data

        except (json.JSONDecodeError, IOError) as e:
            print(f"[WARNING] ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _save_snapshots(self):
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜"""
        self.storage_file.parent.mkdir(parents=True, exist_ok=True)

        try:
            with open(self.storage_file, 'w', encoding='utf-8') as f:
                json.dump(self.snapshots, f, indent=2, ensure_ascii=False)

        except IOError as e:
            print(f"[ERROR] ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
ProgressTracker = ProgressTrackerOptimized


if __name__ == "__main__":
    # ç°¡æ˜“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    print("ProgressTrackerOptimized ç°¡æ˜“ãƒ†ã‚¹ãƒˆ")
    print("-" * 80)

    import tempfile
    import time
    import sys

    # ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        temp_file = Path(f.name)

    try:
        tracker = ProgressTrackerOptimized(temp_file)

        # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼ˆ10,000å•é¡Œ x 3ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰
        print("\n1. å¤§è¦æ¨¡ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆè¨˜éŒ²:")
        base_time = datetime(2025, 1, 1, 0, 0, 0)

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ1ï¼ˆ10,000å•é¡Œï¼‰
        start = time.time()
        tracker.record_snapshot(
            issues=[
                {
                    'file': f'test{i % 100}.py',
                    'line': i,
                    'severity': (i % 10) + 1,
                    'category': ['security', 'performance', 'style'][i % 3]
                }
                for i in range(10000)
            ],
            timestamp=base_time
        )
        elapsed1 = time.time() - start
        print(f"   ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ1è¨˜éŒ²: {elapsed1:.3f}ç§’")

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ2ï¼ˆ8,000å•é¡Œï¼‰
        start = time.time()
        tracker.record_snapshot(
            issues=[
                {
                    'file': f'test{i % 100}.py',
                    'line': i,
                    'severity': (i % 10) + 1,
                    'category': ['security', 'performance', 'style'][i % 3]
                }
                for i in range(8000)
            ],
            timestamp=base_time + timedelta(days=7)
        )
        elapsed2 = time.time() - start
        print(f"   ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ2è¨˜éŒ²: {elapsed2:.3f}ç§’")

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ3ï¼ˆ5,000å•é¡Œï¼‰
        start = time.time()
        tracker.record_snapshot(
            issues=[
                {
                    'file': f'test{i % 100}.py',
                    'line': i,
                    'severity': (i % 10) + 1,
                    'category': ['security', 'performance', 'style'][i % 3]
                }
                for i in range(5000)
            ],
            timestamp=base_time + timedelta(days=14)
        )
        elapsed3 = time.time() - start
        print(f"   ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ3è¨˜éŒ²: {elapsed3:.3f}ç§’")

        # é€²æ—ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("\n2. é€²æ—ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ:")
        start = time.time()
        report = tracker.generate_progress_report()
        elapsed_report = time.time() - start

        print(f"   å‡¦ç†æ™‚é–“: {elapsed_report:.3f}ç§’")
        print(f"   æœŸé–“: {report['period']['start']} â†’ {report['period']['end']}")
        print(f"   å•é¡Œæ•°å¤‰åŒ–: {report['total_issues']['start']}ä»¶ â†’ {report['total_issues']['end']}ä»¶")
        print(f"   å¤‰åŒ–é‡: {report['total_issues']['change']}ä»¶ ({report['total_issues']['change_rate']})")
        print(f"   ãƒˆãƒ¬ãƒ³ãƒ‰: {report['trend']}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        print("\n3. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç¢ºèª:")
        file_size = temp_file.stat().st_size / 1024  # KB
        print(f"   ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} KB")
        print(f"   ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ•°: {len(tracker.snapshots)}")
        print(f"   å¹³å‡ã‚µã‚¤ã‚º/ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: {file_size / len(tracker.snapshots):.2f} KB")

        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ†ã‚¹ãƒˆ
        print("\n4. ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ†ã‚¹ãƒˆ:")
        report_file = temp_file.parent / "progress_report_opt.md"
        tracker.export_progress_report(report_file)

        try:
            print("\nâœ… ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Œäº†")
        except UnicodeEncodeError:
            print("\n[OK] ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Œäº†")

    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        temp_file.unlink(missing_ok=True)
        report_file = temp_file.parent / "progress_report_opt.md"
        report_file.unlink(missing_ok=True)
