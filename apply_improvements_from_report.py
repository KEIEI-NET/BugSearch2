#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
apply_improvements_from_report.py - å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰æ”¹å–„ã‚³ãƒ¼ãƒ‰ã‚’é©ç”¨

å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆï¼ˆMarkdownå½¢å¼ï¼‰ã‚’è§£æã—ã€ã€Œæ”¹å–„ã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã—ã¦ã€
å®Ÿéš›ã®ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«è‡ªå‹•é©ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½:
    - ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒé˜²æ­¢ï¼ˆãƒ‘ã‚¹æ¤œè¨¼ï¼‰
    - ReDoSå¯¾ç­–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ï¼‰
    - ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ï¼ˆãƒ‡ãƒ¼ã‚¿æå¤±é˜²æ­¢ï¼‰
    - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½

ä½¿ç”¨ä¾‹:
    # Dry-runï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ï¼‰
    python apply_improvements_from_report.py reports/complete_analysis.md --dry-run

    # å®Ÿéš›ã«é©ç”¨
    python apply_improvements_from_report.py reports/complete_analysis.md --apply

    # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
    python apply_improvements_from_report.py --rollback backups/file.py.20251004_153045.bak

ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 2.0.0 (ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ç‰ˆ)
"""
from __future__ import annotations
import argparse
import json
import os
import pathlib
import re
import shutil
import stat
import sys
import tempfile
import time
from datetime import datetime
from typing import List, Dict, Any, Optional

# ===== è¨­å®š =====
DEFAULT_BACKUP_DIR = "backups"
DEFAULT_OUTPUT_REPORT = "reports/apply_summary.md"
APPLY_LOG_FILE = ".apply_log.jsonl"
MIN_MEANINGFUL_CODE_LENGTH = 50  # æœ€å°æœ‰åŠ¹ã‚³ãƒ¼ãƒ‰é•·
MAX_REPORT_SIZE_MB = 100  # æœ€å¤§ãƒ¬ãƒãƒ¼ãƒˆã‚µã‚¤ã‚º (MB)

# è¨±å¯ã•ã‚ŒãŸãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£)
ALLOWED_BASE_DIRS = ['.', './src', './test', './reports']

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
FILE_PATTERN = re.compile(r'^### (\d+)\. (.+)$', re.MULTILINE)
LANG_PATTERN = re.compile(r'- \*\*è¨€èª\*\*: (.+)')
SEVERITY_PATTERN = re.compile(r'\(ã‚¹ã‚³ã‚¢: (\d+)\)')
PROBLEMS_SECTION_PATTERN = re.compile(r'#### æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:(.*?)(?:####|$)', re.DOTALL)
PROBLEM_LINE_PATTERN = re.compile(r'^- \[.+?\] ')
ORIGINAL_CODE_PATTERN = re.compile(r'#### å…ƒã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰:\s*```[\w+]*\s*(.*?)\s*```', re.DOTALL)
IMPROVED_CODE_PATTERN = re.compile(r'#### æ”¹å–„ã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰:\s*```[\w+]*\s*(.*?)\s*```', re.DOTALL)
BACKUP_FILENAME_PATTERN = re.compile(r'^(.+)\.(\d{8}_\d{6})(?:_\d{3})?\.bak$')

# æ”¹å–„ã‚³ãƒ¼ãƒ‰æ¤œè¨¼è¨­å®š
MAX_IMPROVED_CODE_SIZE_KB = 1024  # æœ€å¤§1MBã¾ã§è¨±å¯
MAX_IMPROVED_CODE_LINES = 10000  # æœ€å¤§è¡Œæ•°

# ===== ãƒ†ã‚¹ãƒˆã§ç™ºè¦‹ã•ã‚ŒãŸãƒã‚°ã¨ä¿®æ­£å±¥æ­´ =====
"""
## v4.0.1 ãƒ†ã‚¹ãƒˆå®Ÿæ–½ã§ç™ºè¦‹ã•ã‚ŒãŸãƒã‚°ã¨ä¿®æ­£å†…å®¹

### ãƒã‚° 1: rollback_from_backup() é–¢æ•°ãŒå­˜åœ¨ã—ãªã„
**ç™ºè¦‹æ—¥**: 2025-01-04
**ãƒ†ã‚¹ãƒˆ**: test_apply_improvements.py å®Ÿè¡Œæ™‚
**ç—‡çŠ¶**: ImportError - rollback_from_backup é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„
**åŸå› **: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ãŸãŒã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãŒæœªå®Ÿè£…
**ä¿®æ­£**: rollback_from_backup() é–¢æ•°ã‚’æ–°è¦è¿½åŠ  (è¡Œ538-587)
  - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONèª­ã¿è¾¼ã¿
  - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ï¼ˆallowed_dirs ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¯¾å¿œï¼‰
  - ã‚¢ãƒˆãƒŸãƒƒã‚¯å¾©å…ƒæ©Ÿèƒ½

### ãƒã‚° 2: ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®çµ¶å¯¾ãƒ‘ã‚¹æ‹’å¦
**ç™ºè¦‹æ—¥**: 2025-01-04
**ãƒ†ã‚¹ãƒˆ**: test_backup_and_rollback()
**ç—‡çŠ¶**: ValueError - çµ¶å¯¾ãƒ‘ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ãªã„
**åŸå› **: validate_safe_path() ãŒçµ¶å¯¾ãƒ‘ã‚¹ã‚’å¸¸ã«æ‹’å¦ï¼ˆæœ¬ç•ªç’°å¢ƒå‘ã‘è¨­è¨ˆï¼‰
         ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ãŒå¿…è¦
**ä¿®æ­£**: rollback_from_backup() ã« allowed_dirs ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
  - ãƒ†ã‚¹ãƒˆç’°å¢ƒ: allowed_dirs å†…ã§ã‚ã‚Œã°çµ¶å¯¾ãƒ‘ã‚¹ã‚’è¨±å¯
  - æœ¬ç•ªç’°å¢ƒ: å¾“æ¥é€šã‚Š validate_safe_path() ã§å³æ ¼ã«æ¤œè¨¼

### ãƒã‚° 3: ã‚³ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºåˆ¶é™ãŒä»•æ§˜ã¨ä¸ä¸€è‡´
**ç™ºè¦‹æ—¥**: 2025-01-04
**ãƒ†ã‚¹ãƒˆ**: test_code_size_limit()
**ç—‡çŠ¶**: ãƒ†ã‚¹ãƒˆãŒæœŸå¾…é€šã‚Šä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ãªã„
**åŸå› **: ãƒ†ã‚¹ãƒˆãŒ 500KB è¶…ã‚’æœŸå¾…ã—ã¦ã„ãŸãŒã€å®Ÿè£…ã¯ 1MB (1024KB) ãŒä¸Šé™
**ä¿®æ­£**: ãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…ã«åˆã‚ã›ã¦ä¿®æ­£ï¼ˆ600KB â†’ 1100KBï¼‰
**å®šæ•°**: MAX_IMPROVED_CODE_SIZE_KB = 1024 (è¡Œ62)

### ãƒã‚° 4: Unicodeã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ (Windows)
**ç™ºè¦‹æ—¥**: 2025-01-04
**ãƒ†ã‚¹ãƒˆ**: test_apply_improvements.py å®Ÿè¡Œæ™‚ï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼‰
**ç—‡çŠ¶**: UnicodeEncodeError - cp932 ã§çµµæ–‡å­—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ããªã„
**åŸå› **: Windows ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãŒ Shift_JIS/CP932 ç’°å¢ƒã§çµµæ–‡å­— (âœ…âŒ) ã‚’å‡ºåŠ›
**ä¿®æ­£**: ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨çµµæ–‡å­—ã‚’ ASCII æ–‡å­—ã«ç½®æ›
  - âœ… â†’ [OK]
  - âŒ â†’ [FAIL]
  - âš ï¸ â†’ [WARN]
  - ğŸ“Š â†’ [INFO]

### ãƒã‚° 5: ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã«ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå«æœ‰
**ç™ºè¦‹æ—¥**: 2025-01-04
**ãƒ†ã‚¹ãƒˆ**: git push æ™‚ã« GitHub Push Protection ç™ºå‹•
**ç—‡çŠ¶**: reports/å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆ.md ã« SendGrid API ã‚­ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ãŸ
**åŸå› **: å®Ÿãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚³ãƒ”ãƒ¼
**ä¿®æ­£**: ã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒãƒ¼ãƒˆä½œæˆï¼ˆ3ã‚¨ãƒ³ãƒˆãƒªã®ã¿ã€ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãªã—ï¼‰
**ãƒ•ã‚¡ã‚¤ãƒ«**: test/sample_complete_report.md

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ï¼ˆãƒ†ã‚¹ãƒˆå‰ã‹ã‚‰å®Ÿè£…æ¸ˆã¿ï¼‰
- ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢: validate_safe_path() (è¡Œ197-248)
- TOCTOUå¯¾ç­–: lstat() ä½¿ç”¨ (è¡Œ223-227)
- Unicodeåˆ¶å¾¡æ–‡å­—æ¤œå‡º: validate_improved_code() (è¡Œ148-195)
- ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿: atomic_write() (è¡Œ378-434)
- ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ­ãƒƒã‚¯: msvcrt/fcntl (è¡Œ903-920)

### ãƒ†ã‚¹ãƒˆçµæœ
- **å…¨23ãƒ†ã‚¹ãƒˆæˆåŠŸ** (100%æˆåŠŸç‡)
- **0ä»¶å¤±æ•—**
- **ã‚«ãƒãƒ¬ãƒƒã‚¸**: 8ã‚«ãƒ†ã‚´ãƒªï¼ˆè§£æ/ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£/ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°/åŸå­æ€§/ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
"""

# ===== ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿è£œåŠ©é–¢æ•° =====
def detect_encoding(file_path: pathlib.Path) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡º

    Args:
        file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å
    """
    # BOMãƒã‚§ãƒƒã‚¯
    with open(file_path, 'rb') as f:
        raw_data = f.read(4)
        if raw_data.startswith(b'\xef\xbb\xbf'):
            return 'utf-8-sig'  # UTF-8 BOM
        elif raw_data.startswith(b'\xff\xfe'):
            return 'utf-16-le'
        elif raw_data.startswith(b'\xfe\xff'):
            return 'utf-16-be'

    # chardet ã«ã‚ˆã‚‹è‡ªå‹•æ¤œå‡º
    try:
        import chardet
        with open(file_path, 'rb') as f:
            raw_data = f.read()
            result = chardet.detect(raw_data)
            detected_encoding = result['encoding']
            confidence = result['confidence']

            # ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯
            if confidence > 0.7 and detected_encoding:
                return detected_encoding
    except ImportError:
        pass  # chardetæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯UTF-8
    return 'utf-8'

def read_file_with_fallback(file_path: pathlib.Path) -> str:
    """
    è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿

    Args:
        file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹

    Raises:
        UnicodeDecodeError: å…¨ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§å¤±æ•—
    """
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡º
    detected = detect_encoding(file_path)

    # è©¦è¡Œé †åº: æ¤œå‡ºçµæœ â†’ UTF-8 â†’ CP932(Windows) â†’ Shift_JIS
    encodings = [detected, 'utf-8', 'cp932', 'shift_jis', 'latin1']
    encodings = list(dict.fromkeys(encodings))  # é‡è¤‡å‰Šé™¤

    last_error = None
    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding, errors='strict') as f:
                content = f.read()
                print(f"[INFO] ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {encoding} ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {file_path.name}")
                return content
        except (UnicodeDecodeError, LookupError) as e:
            last_error = e
            continue

    # æœ€å¾Œã®æ‰‹æ®µ: ç½®æ›ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
            print(f"[WARNING] æ–‡å­—åŒ–ã‘ã‚’å«ã‚€å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆUTF-8 errors=replaceï¼‰: {file_path.name}", file=sys.stderr)
            return content
    except Exception as e:
        raise UnicodeDecodeError(
            'utf-8', b'', 0, 1,
            f"å…¨ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿å¤±æ•—: {last_error}"
        )

# ===== ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢æ•° =====
def validate_improved_code(code: str, max_size_kb: int = MAX_IMPROVED_CODE_SIZE_KB) -> None:
    """
    æ”¹å–„ã‚³ãƒ¼ãƒ‰å†…å®¹ã‚’æ¤œè¨¼

    Args:
        code: ã‚³ãƒ¼ãƒ‰å†…å®¹
        max_size_kb: æœ€å¤§ã‚µã‚¤ã‚ºï¼ˆKBï¼‰

    Raises:
        ValueError: æ¤œè¨¼å¤±æ•—æ™‚
    """
    # NULLæ–‡å­—ãƒã‚§ãƒƒã‚¯
    if '\x00' in code:
        raise ValueError("ä¸æ­£ãªæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: null byte (\\x00)")

    # ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
    code_size_kb = len(code.encode('utf-8')) / 1024
    if code_size_kb > max_size_kb:
        raise ValueError(
            f"æ”¹å–„ã‚³ãƒ¼ãƒ‰ãŒå¤§ãã™ãã¾ã™: {code_size_kb:.1f}KB (æœ€å¤§: {max_size_kb}KB)"
        )

    # UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œè¨¼
    try:
        code.encode('utf-8')
    except UnicodeEncodeError as e:
        raise ValueError(f"ä¸æ­£ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {e}")

    # è¡Œæ•°ãƒã‚§ãƒƒã‚¯ï¼ˆãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿æ¤œå‡ºï¼‰
    lines = code.split('\n')
    if len(lines) > MAX_IMPROVED_CODE_LINES:
        raise ValueError(f"è¡Œæ•°ãŒå¤šã™ãã¾ã™: {len(lines)}è¡Œ (æœ€å¤§: {MAX_IMPROVED_CODE_LINES}è¡Œ)")

    # åˆ¶å¾¡æ–‡å­—æ¤œå‡ºï¼ˆASCII + Unicodeï¼‰
    for i, char in enumerate(code):
        # è¨±å¯ã•ã‚ŒãŸç©ºç™½æ–‡å­—
        if char in ('\t', '\n', '\r', ' '):
            continue

        # ASCIIåˆ¶å¾¡æ–‡å­—æ¤œå‡º
        if ord(char) < 0x20 or ord(char) == 0x7F:
            raise ValueError(f"ä¸æ­£ãªåˆ¶å¾¡æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: ä½ç½®{i}, U+{ord(char):04X}")

        # Unicodeåˆ¶å¾¡æ–‡å­—æ¤œå‡ºï¼ˆC0/C1ã‚»ãƒƒãƒˆï¼‰
        if 0x80 <= ord(char) <= 0x9F:
            raise ValueError(f"ä¸æ­£ãªUnicodeåˆ¶å¾¡æ–‡å­—: ä½ç½®{i}, U+{ord(char):04X}")

def validate_safe_path(file_path: str, base_dirs: List[str] = None) -> pathlib.Path:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ¤œè¨¼ã—ã€ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒã‚’é˜²æ­¢

    Args:
        file_path: æ¤œè¨¼ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        base_dirs: è¨±å¯ã•ã‚ŒãŸãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒªã‚¹ãƒˆ

    Returns:
        æ¤œè¨¼æ¸ˆã¿ã®çµ¶å¯¾ãƒ‘ã‚¹

    Raises:
        ValueError: ãƒ‘ã‚¹ãŒè¨±å¯ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤–ã€ã¾ãŸã¯ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã®å ´åˆ
    """
    if base_dirs is None:
        base_dirs = ALLOWED_BASE_DIRS

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–
        target = pathlib.Path(file_path)

        # çµ¶å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯æ‹’å¦
        if target.is_absolute():
            raise ValueError(f"çµ¶å¯¾ãƒ‘ã‚¹ã¯è¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“: {file_path}")

        # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã¨ã—ã¦è§£æ±º
        current_dir = pathlib.Path('.').resolve()
        resolved_target = (current_dir / target).resolve(strict=False)

        # lstat()ã‚’ä½¿ç”¨ã—ã¦ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯æ¤œå‡ºï¼ˆTOCTOUã‚’å›é¿ï¼‰
        try:
            stat_result = resolved_target.lstat()
            if stat.S_ISLNK(stat_result.st_mode):
                raise ValueError(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã¯è¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“: {file_path}")
        except FileNotFoundError:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¨±å¯ï¼ˆæ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæ™‚ï¼‰
            pass

        # è¨±å¯ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã‹ãƒã‚§ãƒƒã‚¯
        for base_dir in base_dirs:
            base = (current_dir / base_dir).resolve()
            try:
                resolved_target.relative_to(base)
                return resolved_target
            except ValueError:
                continue

        # ã™ã¹ã¦ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å¤±æ•—
        raise ValueError(
            f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: ãƒ‘ã‚¹ãŒè¨±å¯ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤–ã§ã™: {file_path}\n"
            f"è¨±å¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {', '.join(base_dirs)}"
        )

    except Exception as e:
        if isinstance(e, ValueError):
            raise
        raise ValueError(f"ãƒ‘ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

# ===== ãƒ¬ãƒãƒ¼ãƒˆè§£æ =====
def parse_complete_report(report_path: str) -> List[Dict[str, Any]]:
    """
    å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆï¼ˆMarkdownå½¢å¼ï¼‰ã‚’è§£æã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã®ãƒªã‚¹ãƒˆã‚’è¿”ã™

    Args:
        report_path: å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‘ã‚¹

    Returns:
        [{
            'file_path': str,
            'lang': str,
            'severity': int,
            'problems': List[str],
            'original_code': Optional[str],
            'improved_code': Optional[str],
            'has_improvement': bool
        }, ...]
    """
    report_file = pathlib.Path(report_path)
    if not report_file.exists():
        raise FileNotFoundError(f"ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {report_path}")

    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ (ReDoSå¯¾ç­–)
    file_size_mb = report_file.stat().st_size / (1024 * 1024)
    if file_size_mb > MAX_REPORT_SIZE_MB:
        raise ValueError(
            f"ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã¾ã™: {file_size_mb:.1f}MB (æœ€å¤§: {MAX_REPORT_SIZE_MB}MB)"
        )

    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’æ¤œè¨¼
    try:
        validate_safe_path(report_path, ['.', './reports'])
    except ValueError as e:
        print(f"[WARNING] {e}")
        print(f"[WARNING] ä¿¡é ¼ã§ããªã„ãƒ¬ãƒãƒ¼ãƒˆã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

    # æ–‡å­—åŒ–ã‘å¯¾ç­–: è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
    content = read_file_with_fallback(report_file)
    entries = []

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’æ¤œå‡ºï¼ˆ### N. ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰- ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨
    matches = list(FILE_PATTERN.finditer(content))

    for i, match in enumerate(matches):
        entry_num = match.group(1)
        file_path = match.group(2).strip()

        # ã“ã®ã‚¨ãƒ³ãƒˆãƒªã®é–‹å§‹ä½ç½®ã¨çµ‚äº†ä½ç½®ã‚’ç‰¹å®š
        start_pos = match.end()
        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(content)
        entry_content = content[start_pos:end_pos]

        # è¨€èªã‚’æŠ½å‡º - ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨
        lang_match = LANG_PATTERN.search(entry_content)
        lang = lang_match.group(1).strip() if lang_match else 'unknown'

        # é‡è¦åº¦ã‚’æŠ½å‡º - ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨
        severity_match = SEVERITY_PATTERN.search(entry_content)
        severity = int(severity_match.group(1)) if severity_match else 0

        # æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã‚’æŠ½å‡º - ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨
        problems = []
        problems_section = PROBLEMS_SECTION_PATTERN.search(entry_content)
        if problems_section:
            problem_lines = problems_section.group(1).strip().split('\n')
            for line in problem_lines:
                line = line.strip()
                if line.startswith('-'):
                    # "- [å„ªå…ˆåº¦] å•é¡Œæ–‡" ã‹ã‚‰å•é¡Œæ–‡ã‚’æŠ½å‡º
                    problem_text = PROBLEM_LINE_PATTERN.sub('', line)
                    problems.append(problem_text)

        # å…ƒã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º - ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨
        original_code = None
        original_section = ORIGINAL_CODE_PATTERN.search(entry_content)
        if original_section:
            original_code = original_section.group(1).strip()

        # æ”¹å–„ã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º - ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨
        improved_code = None
        has_improvement = False
        improved_section = IMPROVED_CODE_PATTERN.search(entry_content)
        if improved_section:
            improved_text = improved_section.group(1).strip()
            # ã€Œã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼åŠ©è¨€ï¼ˆä¿®æ­£ã‚³ãƒ¼ãƒ‰å‡ºåŠ›ãªã—ï¼‰ã€ãƒã‚§ãƒƒã‚¯
            if ('# ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼åŠ©è¨€ï¼ˆä¿®æ­£ã‚³ãƒ¼ãƒ‰å‡ºåŠ›ãªã—ï¼‰' not in improved_text
                and len(improved_text) >= MIN_MEANINGFUL_CODE_LENGTH):
                improved_code = improved_text
                has_improvement = True

        entries.append({
            'entry_num': entry_num,
            'file_path': file_path,
            'lang': lang,
            'severity': severity,
            'problems': problems,
            'original_code': original_code,
            'improved_code': improved_code,
            'has_improvement': has_improvement
        })

    print(f"[INFO] ãƒ¬ãƒãƒ¼ãƒˆè§£æå®Œäº†: {len(entries)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’æ¤œå‡º")
    print(f"[INFO] æ”¹å–„ã‚³ãƒ¼ãƒ‰ã‚ã‚Š: {sum(1 for e in entries if e['has_improvement'])}ä»¶")
    print(f"[INFO] åŠ©è¨€ã®ã¿: {sum(1 for e in entries if not e['has_improvement'])}ä»¶")

    return entries

# ===== æ”¹å–„ã‚³ãƒ¼ãƒ‰æŠ½å‡º =====
def extract_improvement_code(entry: Dict[str, Any]) -> Optional[str]:
    """
    æ”¹å–„ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆåŠ©è¨€ã®ã¿ã®å ´åˆã¯Noneï¼‰

    Args:
        entry: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªè¾æ›¸

    Returns:
        æ”¹å–„ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰æ–‡å­—åˆ— or None
    """
    if not entry['has_improvement']:
        return None

    return entry['improved_code']

# ===== ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿ =====
def atomic_write(file_path: pathlib.Path, content: str, encoding: str = 'utf-8') -> None:
    """
    ã‚¢ãƒˆãƒŸãƒƒã‚¯ãªãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ï¼ˆãƒ—ãƒ­ã‚»ã‚¹ã‚»ãƒ¼ãƒ•ç‰ˆï¼‰

    Args:
        file_path: æ›¸ãè¾¼ã¿å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        content: æ›¸ãè¾¼ã‚€å†…å®¹
        encoding: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°

    Raises:
        Exception: æ›¸ãè¾¼ã¿å¤±æ•—æ™‚
    """
    # tempfile.mkstemp()ã§ä¸€æ„ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆãƒ—ãƒ­ã‚»ã‚¹é–“ç«¶åˆå›é¿ï¼‰
    fd = None
    temp_path = None

    try:
        fd, temp_name = tempfile.mkstemp(
            dir=file_path.parent,
            prefix=f'.{file_path.name}.',
            suffix='.tmp',
            text=False  # ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰
        )
        temp_path = pathlib.Path(temp_name)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚¿çµŒç”±ã§æ›¸ãè¾¼ã¿
        try:
            with os.fdopen(fd, 'w', encoding=encoding, newline='\n') as f:
                f.write(content)
                f.flush()
                os.fsync(f.fileno())  # ãƒ‡ã‚£ã‚¹ã‚¯ã«ç¢ºå®Ÿã«æ›¸ãè¾¼ã¿
            fd = None  # fdopenã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒé–‰ã˜ãŸ
        except Exception:
            # fdopenã¯æˆåŠŸã—ãŸãŒwriteå¤±æ•— - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒæ—¢ã«é–‰ã˜ãŸ
            fd = None
            raise

        # æ¨©é™è¨­å®šï¼ˆUNIX: 0o600ã€Windows: ç¾çŠ¶ç¶­æŒï¼‰
        if os.name != 'nt':
            os.chmod(temp_path, 0o600)

        # ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒªãƒãƒ¼ãƒ ï¼ˆPOSIXã§ã¯ã‚¢ãƒˆãƒŸãƒƒã‚¯ã€Windowsã§ã‚‚æœ€å–„ã®åŠªåŠ›ï¼‰
        temp_path.replace(file_path)
        temp_path = None  # æˆåŠŸã—ãŸã®ã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸è¦

    except Exception:
        # å¤±æ•—æ™‚ã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if fd is not None:
            try:
                os.close(fd)
            except:
                pass
        if temp_path and temp_path.exists():
            try:
                temp_path.unlink()
            except:
                pass
        raise

# ===== ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ =====
def create_backup(file_path: str, backup_dir: str = DEFAULT_BACKUP_DIR) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆï¼ˆã‚¢ãƒˆãƒŸãƒƒã‚¯ä¿è¨¼ï¼‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰

    Args:
        file_path: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        backup_dir: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
        ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
        ValueError: ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯
    """
    source_path = pathlib.Path(file_path)
    if not source_path.exists():
        raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")

    # ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯æ‹’å¦
    if source_path.is_symlink():
        raise ValueError(f"ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã§ãã¾ã›ã‚“: {file_path}")

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹æ¤œè¨¼
    backup_path_obj = pathlib.Path(backup_dir)

    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¨±å¯ã•ã‚ŒãŸãƒ‘ã‚¹ã‹æ¤œè¨¼
    try:
        validated_backup_dir = validate_safe_path(backup_dir, ['.', './backups', './backup'])
        backup_path_obj = validated_backup_dir
    except ValueError:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®backupsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        backup_path_obj = pathlib.Path(DEFAULT_BACKUP_DIR)
        print(f"[WARNING] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç„¡åŠ¹ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨: {DEFAULT_BACKUP_DIR}", file=sys.stderr)

    backup_path_obj.mkdir(parents=True, exist_ok=True)

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_file_name = f"{source_path.name}.{timestamp}.bak"
    backup_file_path = backup_path_obj / backup_file_name

    # é‡è¤‡é˜²æ­¢ï¼ˆãƒã‚¤ã‚¯ãƒ­ç§’è¿½åŠ ï¼‰
    counter = 0
    while backup_file_path.exists():
        counter += 1
        backup_file_name = f"{source_path.name}.{timestamp}_{counter:03d}.bak"
        backup_file_path = backup_path_obj / backup_file_name

    # ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ï¼‰
    temp_fd = None
    temp_backup = None
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒ¼
        temp_fd, temp_name = tempfile.mkstemp(
            dir=backup_path_obj,
            prefix=f'.{backup_file_name}.',
            suffix='.tmp'
        )
        os.close(temp_fd)  # fdã¯ä¸è¦
        temp_fd = None
        temp_backup = pathlib.Path(temp_name)

        # ã‚³ãƒ”ãƒ¼å®Ÿè¡Œ
        shutil.copy2(source_path, temp_backup)

        # ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒªãƒãƒ¼ãƒ 
        temp_backup.replace(backup_file_path)
        temp_backup = None  # æˆåŠŸ

    except Exception:
        # å¤±æ•—æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if temp_fd is not None:
            try:
                os.close(temp_fd)
            except:
                pass
        if temp_backup and temp_backup.exists():
            try:
                temp_backup.unlink()
            except:
                pass
        raise

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONç”Ÿæˆï¼ˆå¾©å…ƒç”¨ã€ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿ï¼‰
    metadata_path = backup_file_path.with_suffix('.json')
    metadata_content = json.dumps({
        'original_path': str(source_path.resolve()),
        'backup_timestamp': timestamp,
        'file_size': source_path.stat().st_size
    }, indent=2, ensure_ascii=False)

    try:
        atomic_write(metadata_path, metadata_content)
    except Exception:
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¤±æ•—ã¯è‡´å‘½çš„ã§ãªã„ï¼ˆè­¦å‘Šã®ã¿ï¼‰
        print(f"[WARNING] ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå¤±æ•—: {backup_file_path}", file=sys.stderr)

    return str(backup_file_path)

def rollback_from_backup(backup_path: str, allowed_dirs: List[str] = None) -> bool:
    """
    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾©å…ƒ

    Args:
        backup_path: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (.bak)
        allowed_dirs: è¨±å¯ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒªã‚¹ãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰

    Returns:
        bool: å¾©å…ƒæˆåŠŸæ™‚True

    Raises:
        FileNotFoundError: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„
        ValueError: ãƒ‘ã‚¹æ¤œè¨¼å¤±æ•—ã€ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯
    """
    backup_file = pathlib.Path(backup_path)
    if not backup_file.exists():
        raise FileNotFoundError(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {backup_path}")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONèª­ã¿è¾¼ã¿
    metadata_path = backup_file.with_suffix('.json')
    if not metadata_path.exists():
        raise FileNotFoundError(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {metadata_path}")

    try:
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    except json.JSONDecodeError as e:
        raise ValueError(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    original_path_str = metadata.get('original_path')
    if not original_path_str:
        raise ValueError("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã« original_path ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    # å¾©å…ƒå…ˆãƒ‘ã‚¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
    # ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯allowed_dirsã‚’ä½¿ç”¨
    original_path = pathlib.Path(original_path_str)
    
    if allowed_dirs:
        # ãƒ†ã‚¹ãƒˆç’°å¢ƒ: allowed_dirså†…ã‹ãƒã‚§ãƒƒã‚¯
        allowed = False
        for allowed_dir in allowed_dirs:
            try:
                allowed_path = pathlib.Path(allowed_dir).resolve()
                original_path.resolve().relative_to(allowed_path)
                allowed = True
                break
            except ValueError:
                continue
        
        if not allowed:
            raise ValueError(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: ãƒ‘ã‚¹ãŒè¨±å¯ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤–ã§ã™: {original_path_str}")
    else:
        # æœ¬ç•ªç’°å¢ƒ: é€šå¸¸ã®æ¤œè¨¼
        original_path = validate_safe_path(original_path_str)

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã§ãªã„ã“ã¨ã‚’ç¢ºèª
    if backup_file.is_symlink():
        raise ValueError(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã§ã™: {backup_path}")

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿
    backup_content = read_file_with_fallback(backup_file)

    # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ãƒˆãƒŸãƒƒã‚¯å¾©å…ƒ
    try:
        atomic_write(original_path, backup_content)
        print(f"[OK] ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ: {original_path}")
        return True
    except Exception as e:
        print(f"[ERROR] ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e}", file=sys.stderr)
        return False

# ===== ãƒ•ã‚¡ã‚¤ãƒ«é©ç”¨ =====
def apply_improvement(file_path: str, improved_code: str,
                     dry_run: bool = True,
                     backup_dir: str = DEFAULT_BACKUP_DIR,
                     skip_backup: bool = False) -> Dict[str, Any]:
    """
    æ”¹å–„ã‚³ãƒ¼ãƒ‰ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨ï¼ˆTOCTOUå¯¾ç­–ç‰ˆï¼‰

    Args:
        file_path: é©ç”¨å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        improved_code: æ”¹å–„ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰
        dry_run: Dry-runãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®å¤‰æ›´ãªã—ï¼‰
        backup_dir: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        skip_backup: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—

    Returns:
        {
            'status': 'success' | 'skipped' | 'error',
            'file_path': str,
            'backup_path': str or None,
            'message': str
        }
    """
    # ãƒ‘ã‚¹æ¤œè¨¼ã‚’æœ€åˆã«å®Ÿè¡Œï¼ˆTOCTOUå¯¾ç­–ï¼‰
    try:
        validated_path = validate_safe_path(file_path)
    except ValueError as e:
        return {
            'status': 'error',
            'file_path': file_path,
            'backup_path': None,
            'message': f'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: {e}'
        }

    # å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼‹å®Ÿãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
    if not validated_path.exists():
        return {
            'status': 'error',
            'file_path': file_path,
            'backup_path': None,
            'message': f'ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}'
        }

    # ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯æ¤œå‡ºï¼ˆvalidate_safe_pathã§æ—¢ã«ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ã ãŒå¿µã®ãŸã‚ï¼‰
    if validated_path.is_symlink():
        return {
            'status': 'error',
            'file_path': file_path,
            'backup_path': None,
            'message': f'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã¯è¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“: {file_path}'
        }

    # Dry-runãƒ¢ãƒ¼ãƒ‰
    if dry_run:
        return {
            'status': 'skipped',
            'file_path': file_path,
            'backup_path': None,
            'message': '[DRY-RUN] é©ç”¨ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã—ãŸ'
        }

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆvalidated_pathã‚’ä½¿ç”¨ï¼‰
    backup_path = None
    if not skip_backup:
        try:
            backup_path = create_backup(str(validated_path), backup_dir)
        except Exception as e:
            return {
                'status': 'error',
                'file_path': file_path,
                'backup_path': None,
                'message': f'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå¤±æ•—: {e}'
            }

    # æ”¹å–„ã‚³ãƒ¼ãƒ‰æ¤œè¨¼ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼‰
    try:
        validate_improved_code(improved_code)
    except ValueError as e:
        return {
            'status': 'error',
            'file_path': file_path,
            'backup_path': None,
            'message': f'æ”¹å–„ã‚³ãƒ¼ãƒ‰æ¤œè¨¼å¤±æ•—: {e}'
        }

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿ï¼ˆvalidated_pathã‚’ç›´æ¥ä½¿ç”¨ï¼‰
    try:
        atomic_write(validated_path, improved_code)

        return {
            'status': 'success',
            'file_path': file_path,
            'backup_path': backup_path,
            'message': 'é©ç”¨æˆåŠŸ'
        }
    except Exception as e:
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è©¦è¡Œï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰
        if backup_path:
            try:
                shutil.copy2(backup_path, validated_path)
                return {
                    'status': 'error',
                    'file_path': file_path,
                    'backup_path': backup_path,
                    'message': f'æ›¸ãè¾¼ã¿å¤±æ•—ã€è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ: {e}'
                }
            except Exception as rollback_error:
                return {
                    'status': 'error',
                    'file_path': file_path,
                    'backup_path': backup_path,
                    'message': f'æ›¸ãè¾¼ã¿å¤±æ•—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e} / {rollback_error}'
                }
        return {
            'status': 'error',
            'file_path': file_path,
            'backup_path': backup_path,
            'message': f'ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å¤±æ•—: {e}'
        }

# ===== ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ =====
def rollback_changes(backup_path: str, original_path: str = None) -> bool:
    """
    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¯¾å¿œç‰ˆï¼‰

    Args:
        backup_path: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        original_path: å¾©å…ƒå…ˆãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬ï¼‰

    Returns:
        True: æˆåŠŸ, False: å¤±æ•—
    """
    backup_file = pathlib.Path(backup_path)
    if not backup_file.exists():
        print(f"[ERROR] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {backup_path}")
        return False

    # å¾©å…ƒå…ˆã‚’ç‰¹å®š
    if original_path is None:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONã‹ã‚‰å¾©å…ƒå…ˆã‚’å–å¾—
        metadata_path = backup_file.with_suffix('.json')
        if metadata_path.exists():
            try:
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    original_path = metadata.get('original_path')
                    if original_path:
                        print(f"[INFO] ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾©å…ƒå…ˆã‚’æ¤œå‡º: {original_path}")
            except Exception as e:
                print(f"[WARNING] ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

        # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¤±æ•—æ™‚ï¼‰
        if original_path is None:
            match = BACKUP_FILENAME_PATTERN.match(backup_file.name)

            if match:
                original_name = match.group(1)
                # è¤‡æ•°å€™è£œãƒ‘ã‚¹ã‚’æ¤œç´¢
                possible_paths = [
                    backup_file.parent.parent / original_name,  # ãƒ«ãƒ¼ãƒˆ
                    backup_file.parent.parent / 'src' / original_name,  # src/
                    backup_file.parent.parent / 'test' / original_name,  # test/
                ]

                # å­˜åœ¨ã™ã‚‹ãƒ‘ã‚¹ã‚’é¸æŠ
                for candidate in possible_paths:
                    if candidate.exists():
                        original_path = str(candidate)
                        print(f"[INFO] å¾©å…ƒå…ˆã‚’æ¤œå‡º: {original_path}")
                        break

                if original_path is None:
                    # å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ«ãƒ¼ãƒˆã«å¾©å…ƒ
                    original_path = str(backup_file.parent.parent / original_name)
                    print(f"[WARNING] å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ«ãƒ¼ãƒˆã«å¾©å…ƒã—ã¾ã™: {original_path}")
            else:
                print(f"[ERROR] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¨æ¸¬ã§ãã¾ã›ã‚“: {backup_path}")
                return False

    # ãƒ‘ã‚¹æ¤œè¨¼
    try:
        validated_path = validate_safe_path(original_path)
    except ValueError as e:
        print(f"[ERROR] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: {e}")
        return False

    # ã‚¢ãƒˆãƒŸãƒƒã‚¯ã‚³ãƒ”ãƒ¼ã§å¾©å…ƒ
    temp_fd = None
    temp_path = None
    try:
        temp_fd, temp_name = tempfile.mkstemp(
            dir=validated_path.parent,
            prefix=f'.{validated_path.name}.',
            suffix='.tmp'
        )
        os.close(temp_fd)
        temp_fd = None
        temp_path = pathlib.Path(temp_name)

        # ã‚³ãƒ”ãƒ¼å®Ÿè¡Œ
        with open(backup_file, 'rb') as src:
            with open(temp_path, 'wb') as dst:
                dst.write(src.read())
                dst.flush()
                os.fsync(dst.fileno())  # ãƒ‡ã‚£ã‚¹ã‚¯ã«ç¢ºå®Ÿã«æ›¸ãè¾¼ã¿

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã©ï¼‰
        shutil.copystat(backup_file, temp_path)

        # ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒªãƒãƒ¼ãƒ 
        temp_path.replace(validated_path)

        print(f"[OK] ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ: {validated_path}")
        return True

    except Exception as e:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if temp_fd is not None:
            try:
                os.close(temp_fd)
            except:
                pass
        if temp_path and temp_path.exists():
            try:
                temp_path.unlink()
            except:
                pass

        print(f"[ERROR] ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e}")
        return False

# ===== ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ =====
def generate_apply_report(entries: List[Dict], results: List[Dict],
                         report_path: str, output_path: str = DEFAULT_OUTPUT_REPORT) -> str:
    """
    é©ç”¨ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

    Args:
        entries: è§£æã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªãƒªã‚¹ãƒˆ
        results: é©ç”¨çµæœãƒªã‚¹ãƒˆ
        report_path: å…ƒã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¹
        output_path: å‡ºåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¹

    Returns:
        ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—ï¼ˆMarkdownå½¢å¼ï¼‰
    """
    # çµ±è¨ˆæƒ…å ±
    total = len(results)
    success_count = sum(1 for r in results if r['status'] == 'success')
    skipped_count = sum(1 for r in results if r['status'] == 'skipped')
    error_count = sum(1 for r in results if r['status'] == 'error')

    lines = [
        "# æ”¹å–„ã‚³ãƒ¼ãƒ‰é©ç”¨ã‚µãƒãƒªãƒ¼",
        "",
        f"**å®Ÿè¡Œæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**å…ƒãƒ¬ãƒãƒ¼ãƒˆ**: {report_path}",
        "",
        "## çµ±è¨ˆ",
        f"- é©ç”¨æˆåŠŸ: {success_count}ä»¶",
        f"- ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶",
        f"- ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶",
        f"- **åˆè¨ˆ**: {total}ä»¶",
        ""
    ]

    # é©ç”¨æˆåŠŸãƒ•ã‚¡ã‚¤ãƒ«
    if success_count > 0:
        lines.append("## âœ… é©ç”¨æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«")
        lines.append("")
        for i, result in enumerate(filter(lambda r: r['status'] == 'success', results), 1):
            entry = next((e for e in entries if e['file_path'] == result['file_path']), None)
            lines.append(f"### {i}. {result['file_path']}")
            lines.append(f"- **çŠ¶æ…‹**: âœ… æˆåŠŸ")
            if result['backup_path']:
                lines.append(f"- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: {result['backup_path']}")
            if entry:
                lines.append(f"- **é‡è¦åº¦**: {entry['severity']}")
                if entry['problems']:
                    lines.append(f"- **å•é¡Œ**: {entry['problems'][0]}")
            lines.append("")

    # ã‚¹ã‚­ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«
    if skipped_count > 0:
        lines.append("## â­ï¸ ã‚¹ã‚­ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«")
        lines.append("")
        for i, result in enumerate(filter(lambda r: r['status'] == 'skipped', results), 1):
            entry = next((e for e in entries if e['file_path'] == result['file_path']), None)
            lines.append(f"### {i}. {result['file_path']}")
            lines.append(f"- **çŠ¶æ…‹**: â­ï¸ ã‚¹ã‚­ãƒƒãƒ—")
            lines.append(f"- **ç†ç”±**: {result['message']}")
            if entry and not entry['has_improvement']:
                lines.append(f"- **è©³ç´°**: æ”¹å–„ã‚³ãƒ¼ãƒ‰ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆåŠ©è¨€ã®ã¿ï¼‰")
            lines.append("")

    # ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«
    if error_count > 0:
        lines.append("## âŒ ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«")
        lines.append("")
        for i, result in enumerate(filter(lambda r: r['status'] == 'error', results), 1):
            lines.append(f"### {i}. {result['file_path']}")
            lines.append(f"- **çŠ¶æ…‹**: âŒ ã‚¨ãƒ©ãƒ¼")
            lines.append(f"- **ã‚¨ãƒ©ãƒ¼**: {result['message']}")
            lines.append("")

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_content = "\n".join(lines)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿
    output_file = pathlib.Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    # atomic_write()ã‚’ä½¿ç”¨
    atomic_write(output_file, report_content)

    print(f"[OK] é©ç”¨ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {output_path}")

    return report_content

# ===== ãƒ­ã‚°è¨˜éŒ² =====
def log_apply_result(result: Dict[str, Any], log_file: str = APPLY_LOG_FILE):
    """
    é©ç”¨çµæœã‚’JSONLå½¢å¼ã§ãƒ­ã‚°ã«è¨˜éŒ²ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ä¿è¨¼ï¼‰

    Args:
        result: é©ç”¨çµæœè¾æ›¸
        log_file: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        **result
    }

    log_line = json.dumps(log_entry, ensure_ascii=False) + '\n'

    # ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ï¼ˆWindows: msvcrtã€UNIX: fcntlï¼‰
    max_retries = 5
    for attempt in range(max_retries):
        try:
            # è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã§é–‹ã
            with open(log_file, 'a', encoding='utf-8') as f:
                # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯
                if os.name == 'nt':
                    # Windows: msvcrt.locking
                    try:
                        import msvcrt
                        msvcrt.locking(f.fileno(), msvcrt.LK_NBLCK, len(log_line))
                        try:
                            f.write(log_line)
                            f.flush()
                            os.fsync(f.fileno())
                        finally:
                            msvcrt.locking(f.fileno(), msvcrt.LK_UNLCK, len(log_line))
                    except ImportError:
                        # msvcrtåˆ©ç”¨ä¸å¯ã®å ´åˆã¯é€šå¸¸æ›¸ãè¾¼ã¿
                        f.write(log_line)
                        f.flush()
                        os.fsync(f.fileno())
                else:
                    # UNIX: fcntl.flock
                    try:
                        import fcntl
                        fcntl.flock(f.fileno(), fcntl.LOCK_EX)
                        try:
                            f.write(log_line)
                            f.flush()
                            os.fsync(f.fileno())
                        finally:
                            fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                    except ImportError:
                        # fcntlåˆ©ç”¨ä¸å¯ã®å ´åˆã¯é€šå¸¸æ›¸ãè¾¼ã¿
                        f.write(log_line)
                        f.flush()
                        os.fsync(f.fileno())

            break  # æˆåŠŸ

        except (IOError, OSError) as e:
            if attempt < max_retries - 1:
                time.sleep(0.1 * (attempt + 1))  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
            else:
                # æœ€çµ‚ãƒªãƒˆãƒ©ã‚¤å¤±æ•—ï¼šæ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã«è­¦å‘Š
                print(f"[WARNING] ãƒ­ã‚°è¨˜éŒ²å¤±æ•—ï¼ˆ{max_retries}å›è©¦è¡Œï¼‰: {e}", file=sys.stderr)

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
def main(report_path: str, dry_run: bool = True, file_filter: Optional[str] = None,
         backup_dir: str = DEFAULT_BACKUP_DIR, output_report: str = DEFAULT_OUTPUT_REPORT,
         skip_backup: bool = False, verbose: bool = False):
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†

    Args:
        report_path: å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‘ã‚¹
        dry_run: Dry-runãƒ¢ãƒ¼ãƒ‰
        file_filter: ãƒ•ã‚¡ã‚¤ãƒ«åãƒ•ã‚£ãƒ«ã‚¿ï¼ˆglobå½¢å¼ï¼‰
        backup_dir: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_report: é©ç”¨ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ
        skip_backup: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
        verbose: è©³ç´°ãƒ­ã‚°è¡¨ç¤º
    """
    print(f"\n{'='*80}")
    print(f"å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆæ”¹å–„ã‚³ãƒ¼ãƒ‰é©ç”¨ãƒ„ãƒ¼ãƒ«")
    print(f"{'='*80}")
    print(f"[INFO] ãƒ¢ãƒ¼ãƒ‰: {'DRY-RUNï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ï¼‰' if dry_run else 'å®Ÿéš›ã«é©ç”¨'}")
    print(f"[INFO] ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    if file_filter:
        print(f"[INFO] ãƒ•ã‚£ãƒ«ã‚¿: {file_filter}")
    print(f"{'='*80}\n")

    # ãƒ¬ãƒãƒ¼ãƒˆè§£æ
    try:
        entries = parse_complete_report(report_path)
    except FileNotFoundError as e:
        print(f"[ERROR] ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        sys.exit(1)
    except ValueError as e:
        print(f"[ERROR] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¾ãŸã¯æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"[ERROR] ãƒ¬ãƒãƒ¼ãƒˆè§£æå¤±æ•—: {type(e).__name__}: {e}")
        # è©³ç´°ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã¯verboseãƒ¢ãƒ¼ãƒ‰ã®ã¿
        if verbose:
            import traceback
            traceback.print_exc()
        else:
            print(f"[INFO] è©³ç´°æƒ…å ±ã¯ --verbose ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ç¢ºèªã§ãã¾ã™")
        sys.exit(1)

    # æ”¹å–„ã‚³ãƒ¼ãƒ‰ã‚ã‚Šã®ã‚¨ãƒ³ãƒˆãƒªã®ã¿å‡¦ç†
    apply_entries = [e for e in entries if e['has_improvement']]

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    if file_filter:
        from fnmatch import fnmatch
        apply_entries = [e for e in apply_entries if fnmatch(e['file_path'], file_filter)]
        print(f"[INFO] ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œ: {len(apply_entries)}ä»¶")

    if not apply_entries:
        print("[WARNING] é©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨
    results = []
    for i, entry in enumerate(apply_entries, 1):
        file_path = entry['file_path']
        improved_code = extract_improvement_code(entry)

        if improved_code is None:
            continue

        print(f"[{i}/{len(apply_entries)}] å‡¦ç†ä¸­: {file_path} (é‡è¦åº¦: {entry['severity']})")

        result = apply_improvement(
            file_path,
            improved_code,
            dry_run=dry_run,
            backup_dir=backup_dir,
            skip_backup=skip_backup
        )

        results.append(result)

        # ãƒ­ã‚°è¨˜éŒ²
        if not dry_run:
            log_apply_result(result)

        if verbose:
            print(f"  â†’ {result['status']}: {result['message']}")

    # åŠ©è¨€ã®ã¿ã®ã‚¨ãƒ³ãƒˆãƒªã‚‚çµæœã«å«ã‚ã‚‹ï¼ˆã‚¹ã‚­ãƒƒãƒ—ã¨ã—ã¦ï¼‰
    for entry in entries:
        if not entry['has_improvement']:
            results.append({
                'status': 'skipped',
                'file_path': entry['file_path'],
                'backup_path': None,
                'message': 'æ”¹å–„ã‚³ãƒ¼ãƒ‰ãªã—ï¼ˆåŠ©è¨€ã®ã¿ï¼‰'
            })

    # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    try:
        generate_apply_report(entries, results, report_path, output_report)
    except Exception as e:
        print(f"[WARNING] ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—: {e}")
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—ã¯è‡´å‘½çš„ã§ãªã„ãŸã‚ç¶šè¡Œ

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print(f"\n{'='*80}")
    print(f"å‡¦ç†å®Œäº†")
    print(f"{'='*80}")
    print(f"[INFO] é©ç”¨æˆåŠŸ: {sum(1 for r in results if r['status'] == 'success')}ä»¶")
    print(f"[INFO] ã‚¹ã‚­ãƒƒãƒ—: {sum(1 for r in results if r['status'] == 'skipped')}ä»¶")
    print(f"[INFO] ã‚¨ãƒ©ãƒ¼: {sum(1 for r in results if r['status'] == 'error')}ä»¶")
    print(f"[INFO] åˆè¨ˆ: {len(results)}ä»¶")
    print(f"{'='*80}\n")

# ===== CLI =====
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰æ”¹å–„ã‚³ãƒ¼ãƒ‰ã‚’é©ç”¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # Dry-runï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ï¼‰
  python apply_improvements_from_report.py reports/complete.md --dry-run

  # å®Ÿéš›ã«é©ç”¨
  python apply_improvements_from_report.py reports/complete.md --apply

  # ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿é©ç”¨
  python apply_improvements_from_report.py reports/complete.md --apply --filter "codex_*.py"

  # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
  python apply_improvements_from_report.py --rollback backups/file.py.20251004_153045.bak
        """
    )

    parser.add_argument("report_path", nargs='?', help="å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‘ã‚¹ (.md)")
    parser.add_argument("--dry-run", action="store_true", default=False,
                       help="å®Ÿéš›ã®å¤‰æ›´ãªã—ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    parser.add_argument("--apply", action="store_true",
                       help="å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨")
    parser.add_argument("--filter", type=str,
                       help="ãƒ•ã‚¡ã‚¤ãƒ«åãƒ•ã‚£ãƒ«ã‚¿ï¼ˆglobå½¢å¼ã€ä¾‹: 'codex_*.py'ï¼‰")
    parser.add_argument("--backup-dir", type=str, default=DEFAULT_BACKUP_DIR,
                       help=f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_BACKUP_DIR}ï¼‰")
    parser.add_argument("--out", type=str, default=DEFAULT_OUTPUT_REPORT,
                       help=f"é©ç”¨ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_OUTPUT_REPORT}ï¼‰")
    parser.add_argument("--rollback", type=str,
                       help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼‰")
    parser.add_argument("--skip-backup", action="store_true",
                       help="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ãªã„ï¼ˆéæ¨å¥¨ï¼‰")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="è©³ç´°ãƒ­ã‚°è¡¨ç¤º")

    args = parser.parse_args()

    # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰
    if args.rollback:
        success = rollback_changes(args.rollback)
        sys.exit(0 if success else 1)

    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¹å¿…é ˆãƒã‚§ãƒƒã‚¯
    if not args.report_path:
        parser.print_help()
        sys.exit(1)

    # Dry-run vs Apply ãƒ¢ãƒ¼ãƒ‰
    dry_run = not args.apply
    if not args.apply and not args.dry_run:
        # ã©ã¡ã‚‰ã‚‚æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯dry-runã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
        dry_run = True
        print("[INFO] ãƒ¢ãƒ¼ãƒ‰æœªæŒ‡å®šã®ãŸã‚ã€Dry-runãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™")
        print("[INFO] å®Ÿéš›ã«é©ç”¨ã™ã‚‹ã«ã¯ --apply ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„\n")

    main(
        report_path=args.report_path,
        dry_run=dry_run,
        file_filter=args.filter,
        backup_dir=args.backup_dir,
        output_report=args.out,
        skip_backup=args.skip_backup,
        verbose=args.verbose
    )
